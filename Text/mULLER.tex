\documentclass[anon]{nesy2025} % Anonymized submission for Openreview
%\documentclass[draft]{nesy2025} % Uncomment to include author names

 % The following packages will be automatically loaded:
 % amsmath, amssymb, natbib, graphicx, url, algorithm2e

 %\usepackage{rotating}% for sideways figures and tables
\usepackage{longtable}% for long tables

 % The booktabs package is used by this sample document
 % (it provides \toprule, \midrule and \bottomrule).
 % Remove the next line if you don't require it.
\usepackage{booktabs}


% ---------- packages ----------
\usepackage[show]{ed}
\usepackage{authblk}
\usepackage{mathrsfs,amsopn}
\usepackage{hyperref}
\usepackage{stmaryrd}
\usepackage{tikz}
  \usetikzlibrary{positioning,backgrounds,cd}
  \tikzset{line/.style={draw=black,line width=1pt}}
  
% Then load only the arrow and matrix modules of Xy-pic to avoid redefining &
\usepackage[arrow,matrix]{xy}
\usepackage{quiver}
\usepackage{enumitem}
\usepackage{cmll}      % linear-logic symbols (\with, \parr, etc.)
% \usepackage{mathabx}  % Commented out to avoid font conflicts
\usepackage{bbold}

% The following command is just for this sample document:
\newcommand{\cs}[1]{\texttt{\char`\\#1}}

% ---------- operators ----------
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
% basic signature helpers
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\cod}{cod}
\DeclareMathOperator{\ari}{ari}
\DeclareMathOperator{\etaa}{eta}
\newcommand{\fub}{\mathcal{F}}
\newcommand{\Rel}{\mathrm{Rel}}
\newcommand{\Func}{\mathrm{Func}}
\newcommand{\Const}{\mathrm{Const}}
\newcommand{\Dom}{\mathrm{Dom}}
\newcommand{\Sub}[1]{\mathrm{Sub}_{\mathcal{C}}\!\bigl[#1\bigr]}
\newcommand{\SubC}{\operatorname{Sub}_{\mathcal{C}}}
\newcommand{\Elm}[1]{\mathrm{Elm}_{\mathcal{C}}\!\bigl[#1\bigr]}
\newcommand{\ObC}{\mathrm{Ob}_{\mathcal{C}}}
\newcommand{\longhookrightarrow}{\lhook\joinrel\longrightarrow}
\newcommand\sem[1]{\llbracket #1 \rrbracket}
\providecommand{\Set}{\mathbf{Set}}
\providecommand{\Meas}{\mathbf{Meas}}
\providecommand{\HeytAlg}{\mathbf{HeytAlg}}
\providecommand{\Cat}{\mathbf{Cat}}
\providecommand{\Stoch}{\mathbf{Stoch}}
\providecommand{\Kl}[1]{\mathcal{K}\!\ell\!\bigl(#1\bigr)}
\providecommand{\Hom}{\operatorname{Hom}}
\providecommand{\id}{\mathrm{id}}
\providecommand{\comp}{\mathbin{\circ}}
\providecommand{\MSig}{\mathsf{MSig}}
\providecommand{\bigsqcupindexed}[2]{\bigsqcup_{#1}#2}
\providecommand{\CRL}{\mathbf{CRL}} 
\providecommand{\CRL}{\mathbf{CRL}}
\providecommand{\BL}{\mathbf{BLAlg}}  
\providecommand{\Sort}{\mathrm{Sort}}
\newcommand{\F}{\mathrm{F}}
\newcommand{\MF}{\mathrm{MF}}
\renewcommand{\P}{\mathrm{P}}
\newcommand{\MP}{\mathrm{MP}}

% monadic helper macros
\newcommand{\MConst}{\mathrm{MConst}}
\newcommand{\MProp}{\mathrm{MProp}}
\newcommand{\MPrps}{\mathrm{MPrps}}
\newcommand{\MPred}{\mathrm{MPred}}
\providecommand{\MFunc}{\mathrm{MFunc}}
\newcommand{\MRel}{\mathrm{MRel}}

% logic helpers
\newcommand{\PV}{\mathsf{PV}}
% logical lexicon symbol
\newcommand{\Chi}{\mathcal X}

\providecommand{\Pred}{\mathsf{Pred}}
\newcommand{\Prps}{\mathsf{Prps}}

% logical-lexicon helper macros
\newcommand{\Con}{\mathsf{Con}}
\newcommand{\Quant}{\mathsf{Quant}}
\newcommand{\BVar}{\mathsf{BVar}}
\newcommand{\FVar}{\mathsf{FVar}}

% Property symbols (\Prop)
\providecommand{\Prop}{\mathrm{Prop}}

% Maps functor (used in Definition~\ref{def:function‐monad})
\newcommand{\Maps}{\operatorname{Maps}}

% Uniform averaging operator
\DeclareMathOperator{\Unif}{Unif}


 % Define an unnumbered theorem just for this sample document:
\theorembodyfont{\upshape}
\theoremheaderfont{\scshape}
\theorempostheader{:}
\theoremsep{\newline}
\newtheorem*{note}{Note}




\title[Monadic ULLER]{mULLER: A Modular Categorical Semantics of the Neurosymbolic ULLER Framework via Monads}

 % Use \Name{Author Name} to specify the name.

 % Spaces are used to separate forenames from the surname so that
 % the surnames can be picked up for the page header and copyright footer.
 
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % *** Make sure there's no spurious space before \nametag ***

 % Two authors with the same address
  \clearauthor{\Name{Daniel {Romero Schellhorn}} \Email{d.schellhorn@uni-osnabrueck.de}\\
   \Name{Till Mossakowski} \Email{till.mossakowski@uni-osnabrueck.de}\\

   \addr University of Osnabrück, Osnabrück, Germany}

 % Three or more authors with the same address:
 % \author{\Name{Author Name1} \Email{an1@sample.com}\\
 %  \Name{Author Name2} \Email{an2@sample.com}\\
 %  \Name{Author Name3} \Email{an3@sample.com}\\
 %  \Name{Author Name4} \Email{an4@sample.com}\\
 %  \Name{Author Name5} \Email{an5@sample.com}\\
 %  \Name{Author Name6} \Email{an6@sample.com}\\
 %  \Name{Author Name7} \Email{an7@sample.com}\\
 %  \Name{Author Name8} \Email{an8@sample.com}\\
 %  \Name{Author Name9} \Email{an9@sample.com}\\
 %  \Name{Author Name10} \Email{an10@sample.com}\\
 %  \Name{Author Name11} \Email{an11@sample.com}\\
 %  \Name{Author Name12} \Email{an12@sample.com}\\
 %  \Name{Author Name13} \Email{an13@sample.com}\\
 %  \Name{Author Name14} \Email{an14@sample.com}\\
 %  \addr Address}


 % Authors with different addresses:
 % \author{\Name{Daniel {Romero Schellhorn}} \Email{d.schellhorn@uni-osnabrueck.de}\\
 % \addr University of Osnabrück, Osnabrück, Germany
 % \AND
 % \Name{Till Mossakowski} \Email{till.mossakowski@uni-osnabrueck.de}\\
 % \addr University of Osnabrück, Osnabrück, Germany}
 %}

\begin{document}

\maketitle
\begin{abstract}
\textbf{ULLER} (\underline{U}nified \underline{L}anguage for \underline{LE}arning and \underline{R}easoning) provides a single first‑order logic (FOL) syntax whose knowledge bases can be used without modification by a broad range of neurosymbolic systems. \ednote{ \textbf{Daniel}: Introduce the word MULLER here: noun, a heavy tool of stone or iron (usually with a flat base and a handle) that is used to grind and mix material.}
The original specification endows this syntax with three pairwise independent semantics—classical, fuzzy, and probabilistic—each accompanied by dedicated semantic rules.  
We prove that these seemingly disparate semantics are all instances of one categorical framework based on \emph{monads}, the very construct that models side effects in functional programming.  
This enables the \emph{modular} addition of new semantics and systematic translations between them. As examples , we outline the addition of LTN, STL, possibilistic and continuous fuzzy semantics and their relations. In particular, our approach allows a modular implementation of ULLER in Python and Haskell.\ednote{ \textbf{sLXz}: "One should not expect to unify everything under the same framework that will then become so abstract as to have no practical value. More discussion of how Haskell could be deployed as claimed in the abstract would be valuable."} As a further outcome, we generalize quantification in Logic Tensor Networks (LTN) to arbitrary (also infinite) domains by extending the Giry monad to probability spaces.\ednote{ \textbf{1Fh6}: "The abstract claims it 'proves' that several semantics are instances of their categorical framework. However proofs of these equivalences are missing."}
\end{abstract}

 \section{Introduction}
\label{sec:intro}

Neurosymbolic integration is a rapidly developing branch of AI.
In the past, numerous heterogeneous approaches have emerged, each with its own code base. \cite{vankriekenULLERUnifiedLanguage2024} introduces ULLER, a unified neurosymbolic library that aspires to play for neurosymbolic systems the role that TensorFlow and PyTorch play for deep-learning workflows. Their theoretical core is the concept of a NeSy system: standard first-order logic enriched with neural components. In particular, formulas of the form
$$x:=m(T_1,\dots,T_n)(F)$$
are used to integrate neural models $m$ into logical formulas.
These models leave the platonic logical world of objects and truth values.\ednote{ \textbf{1Fh6}: "What is meant with the 'platonic logical world' of objects and truth values?"}
Instead, they perform computations that may return multiple values and typically involve non-determinism or probability distributions as illustrated in their following toy example:
$$x := dice() (x = 6 \wedge even(x))$$
throws a die once, and checks whether it is 6 and even (so the resulting probability is $\frac{1}{6}$), whereas
$$x := dice() (x = 6) \wedge x:= dice() (even(x))$$
throws a die twice, and checks whether the first one is 6 and the second one is even (so the resulting probability is $\frac{1}{12}$).
With neural classifiers, regressions or other machine learning models in place of the $dice()$ function,
one obtains a neurosymbolic first-order logic.
\ednote{ \textbf{3Pt1}: "If you add computational predicates, how do these fit within the scoping concerns of ULLER? How to have them as one (cf the first dice example)?"}
However, the notion of NeSy system in \cite{vankriekenULLERUnifiedLanguage2024} has several shortcomings:\ednote{ \textbf{sLXz}: "The main criticisms of ULLER may not be warranted. What is seen as shortcomings seem to be features, ULLER being intended as a unified library or framework."}
\begin{itemize}
\item
  There is no uniform inductive definition of truth, i.e.\ of the truth value of a sentence in an interpretation. Rather, the notion of NeSy system has the inductive interpretation function as a component, meaning that classical, probabilistic and fuzzy NeSy systems employ three different inductive definitions of truth. Parts of these definitions of truth are copied verbatim from one NeSy system to another, other parts need to be replaced. This duplication of semantic rules is not modular.\ednote{ \textbf{sLXz}: "The claim of 'duplication of semantic rules' seems to miss the point of the 'library'. There are differences in the various NeSy approaches being accounted for."} By contrast, we aim at a truly uniform inductive definition of truth value that is independent of the NeSy system and hence can be reused for different NeSy systems, such that the NeSy system itself is a parameter of the inductive definition of truth.
%\item
%  The definition of truth for the classical case is flawed. In the NeSy system for classical two-valued logic, there is the need for a transition from continuous truth values in $[0,1]$ to classical truth values $\{0,1\}$.
%  In this context, there is the need to obtain an individual that maximises the truth value of a given formula. Here, argmax is used. However, there might be several objects leading to the same maximal truth value. There is no satisfactory straightforward fix for this problem. For example, assuming a total order on domains would allow to resolve this ambiguity by taking the first maximum according to this order, but this is rather ad-hoc and often not what is intended.
\item
  The case of continuous probability distributions (involving probability kernels or Markov kernels) is not covered faithfully, because in this case, measurable spaces are required to properly define the mentioned Markov kernels. However, measurable spaces are not considered in \cite{vankriekenULLERUnifiedLanguage2024}.
\item
  The treatment of logical connectives is not uniform across NeSy systems, i.e.\ the different sets of connectives are not considered as instances of a common abstract (algebraic) notion. Moreover, predicates are only two-valued and not e.g.\ fuzzy. Also, quantifiers in probabilistic semantics are defined using possibly infinite products, without requiring a suitable order structure on domains and without discussing convergence. 
%\item
%  The fuzzy semantics of the (computational) function symbols is not thoroughly motivated and is only given in the finite case. It also tries to interpret fuzzy or differentiable predicates which is unnecessary, if those are directly interpreted in a fuzzy or differentiable way.\ednote{I do not understand this.}
\item
  The high‑level concepts of semantics and computation are not properly separated.\ednote{ \textbf{sLXz}: "Focus more on the semantics versus computation aspect - this discussion is by itself a relevant contribution."} Computation (namely sampling) is mixed into the semantics at least in two places. The first one in the classical semantics, where the possibly multi-valued $\argmax$ can only be properly evaluated using sampling. We conceptualize the $\argmax$ differently as a transition \emph{between} semantics. The second time is in "Sampling Semantics", which is not really semantics but computation (sampling).%\ednote{We already address argmax in the second point. Merge them?}
\end{itemize}

\noindent
We argue that ULLER is conceptually robust and show that a monadic formulation resolves all of the foregoing issues.\ednote{ \textbf{1Fh6}: "I did not entirely follow the point about disentangling choices and how Monadic ULLER resolves this (in the end)"}
In particular, ULLER formulas of the form
$$x:=m(T_1,\dots,T_n)(F)$$
can be modeled using Moggi's notion of computational monad \cite{moggiNotionsComputationMonads1991}, which has been introduced to model side effects in (functional) programming. Although monads originate in category theory, we always begin with a concrete presentation over the category $\mathbf{Set}$ (that can be understood without any knowledge of category theory) and only then sketch the generalization to an arbitrary cartesian closed category.
\ednote{ \textbf{3Pt1}: "Add more intuitions and concrete examples - the examples quickly delve into abstract notations without developing intuitions."}


%
\section{Neurosymbolic frameworks}
\label{sec:neurosymbolic-frameworks}

A neurosymbolic framework (NeSy framework) is the general framework for a system that combines neural models with symbolic logic, and that provides the semantic background for the specific logic involved.
Examples are the logics behind DeepProbLog \cite{DBLP:journals/ai/ManhaeveDKDR21} or Logic Tensor Networks \cite{DBLP:journals/ai/BadreddineGSS22}.\ednote{ \textbf{sLXz}: "Provide some examples of the benefit of the framework when applied directly to e.g. LTN and DeepProbLog. This should offer a direct kind of comparative presentation of results."} The notion of NeSy framework is not defined in \cite{vankriekenULLERUnifiedLanguage2024}. Rather, they define a notion of NeSy system, which is quite ad-hoc, because it makes a fundamental choice about the logic, while simultaneously being based on a particular interpretation, i.e.\ a particular choice of a neural and logical model.
Our notion of NeSy framework provides a means to disentangle these choices. A particular NeSy framework can be used to define different NeSy systems, while \cite{vankriekenULLERUnifiedLanguage2024} needs to individually bake in the framework into each system, causing semantic rule duplication.

%
\subsection{Monads}
\label{subsec:monads}
\ednote{ \textbf{1Fh6}: "Please mark this section as background. The text at the beginning suggests the rest of this section is about explaining, however this only happens later."}
We interpret formulas $x:=m(T_1,\dots,T_n)(F)$ involving neural models $m$ (=certain computations) using Moggi's notion of computational monad \cite{moggiNotionsComputationMonads1991} in the form of Kleisli triples:\ednote{ \textbf{sLXz}: "Please explain the notation to the non-expert even if that's standard in abstract algebra: if m is a neural net, what is T and what is F?"}

\begin{definition} \label{def:set_Kleisli_triple}
A \textbf{set-based Kleisli triple} $(\mathcal{T}, \eta, (-)^*)$  consists of:
\begin{itemize}
  \item A mapping $\mathcal{T}$ mapping a set $X$ to the set $\mathcal{T}X$ (of computations with values from $X$),
  \item A family of functions: $\eta_X : X \to \mathcal{T} X$ for each set $X$ (construing a value $a\in X$ as stateless computation $\eta_X(a)\in \mathcal{T} X$),
  \item A function that assigns to each function $f : X \to \mathcal{T} Y$ a function $f^* : \mathcal{T} X \to \mathcal{T} Y$ (called the \emph{Kleisli extension}), needed for sequential composition of computations\footnote{Namely, $f : X \to \mathcal{T} Y$ and $g : Y \to \mathcal{T} Z$ can be composed to $g^*\circ f : X \to \mathcal{T} Z$.},
\end{itemize}
such that the following axioms hold:
\begin{enumerate}
  \item $(\eta_X)^* = \mathrm{id}_{\mathcal{T} X}$,
  \item $f^* \circ \eta_X = f$ for all $f : X \to \mathcal{T} Y$,
  \item $(g^* \circ f)^* = g^* \circ f^*$ for all $f : X \to \mathcal{T} Y$ and $g : Y \to \mathcal{T} Z$.
\end{enumerate}
\end{definition}

\begin{example}\label{ex:dist-monads}
\leavevmode
\textbf{Probability distribution monad (Kleisli triple) \(\mathcal D\) on \(\Set\).}
\[
  \mathcal D X := \Bigl\{\,
     \rho:X\to[0,1]\;\Bigm|\;
     \text{$\rho$ has finite support and }\sum_{x\in X}\rho(x)=1
   \Bigr\},
\]
\[
  \eta_X(x):=\delta_x, \; \delta_x(y)=\left\{\begin{array}{l}1,\ x=y\\0,\ x\not=y\end{array}\right.\ 
  f^{*}(\rho)(y):=\sum_{x\in X}\!\rho(x)f(x)(y)
  \quad\bigl(f:X\!\to\!\mathcal D Y,\; \rho\in\mathcal D X\bigr).
\]
\ednote{ \textbf{1Fh6}: "The definition of $f^*$ sums over $x\in X$, however this is only possible if $X$ is countable. I think the sum should be over the support of $\rho$."}
\end{example}

\ednote{
  \textbf{3Pt1}: "in Example 1, I do not understand if delta x which associates to each element x of X  degenerate distribution with all probability mass in x, is supposed to be a simple example of a probabilistic system or if it is defined for all probabilistic systems. I also don't understand the purpose of f*(rho)
  , can it be understood as computing the expected value of a computation? "
}


\paragraph{Categorical generalisation:}
A Kleisli triple on a category $\mathcal{C}$ involves a mapping of objects $\mathcal{T}: \mathrm{Ob}(\mathcal{C}) \to \mathrm{Ob}(\mathcal{C})$, a family of morphisms $\eta_X : X \to \mathcal{T} X$ for each object $X$ in $\mathcal{C}$ (called the \emph{unit}), and a function that assigns to each morphism $f : X \to \mathcal{T} Y$ a morphism $f^* : \mathcal{T} X \to \mathcal{T} Y$ 
such that the axioms hold as in Def.~\ref{def:set_Kleisli_triple}.
Note that a set-based Kleisli triple is then a Kleisli triple on the category $\Set$.\ednote{ \textbf{1Fh6}: "Please specify why this generalisation is needed at this point."}

\begin{example}\label{ex:giry-monad}
\leavevmode
\textbf{Giry monad (Kleisli triple) \(\mathcal G\) on \(\Meas\), the category of measurable spaces and maps.}
For a measurable space \((X,\Sigma_X)\)
\[
  \mathcal G(X,\Sigma_X)
    := \bigl\{\text{probability measures }\rho\text{ on }(X,\Sigma_X)\bigr\},
\]
\[
  \eta_{(X,\Sigma_X)}(x):=\delta_x,~~~
  f^{*}(\rho)(A):=\int\limits_{X}\!f(x)(A) d\rho(x)
  \quad\bigl(f:(X,\Sigma_X)\!\to\!\mathcal G(Y,\Sigma_Y), A\subseteq X\text{ measurable}\bigr).
\]
\ednote{ \textbf{1Fh6}: "Please specify $\delta_x$ is the dirac measure."}
\end{example}


\subsection{Double Commutative Monoid Lattices}
\label{subsec:2CMon-Lat}
We need an algebraic structure to model the space of truth values. We weaken the notion of BL algebra \cite{hajekMetamathematicsFuzzyLogic1998} used in fuzzy logic as follows:
% Heyting Algebras, DeMorgan Algebras, and Continuous Semirings\footnote{See \cite{karnerContinuousMonoidsSemirings2004a} for more info.}, and therefore covers Classical, Basic Fuzzy,  Intuitionistic, Belnap, and Probabilistic logics respectively. ULLER uses classical, basic fuzzy or probabilistic logical connectives.
%\footnote{To actually define models in a clean categorical way, we need to pass from mere BL-algebras to hyperdoctrines generalized to BL-algebras or even some form of residual lattices. See \url{https://ncatlab.org/nlab/show/relation+between+type+theory+and+category+theory} for an overview of the current state of research and also \cite{galatosSurveyGeneralizedBasic2009}[p. 5] for the details of algebra inclusions.} 

\begin{definition}[Double Commutative Monoid Lattice (2CMon-Lat)]\label{def:2CMon-Lat}
A \emph{double commutative monoid lattice}\footnote{This is a generalization of residual lattices to also include BL algebras, Heyting Algebras, DeMorgan Algebras and Continuous Semirings. It is inspired by residual lattices as in \cite{hajekMetamathematicsFuzzyLogic1998} and also by quantales. Logician's note: in accordance with the NeSy literature, we will not differentiate between weak and strong connectives; however, this could easily be adapted.} is a tuple
\[
  \bigl(S, \; 0, \; 1, \; \leq,\;\otimes,\;\oplus,\;\to \bigr)
\]
in which $S$ is a set and $\mathcal{L}:=(S,\leq,0,1)$ forms a bounded lattice.  We have the \emph{smallest element} $0  \in S$ and \emph{largest element} $1 \in S$.\ednote{ \textbf{1Fh6}: "What is $\mathcal{L}$? Remind the reader that $\mathcal{L}$ is a lattice"}
% and  the \emph{meet} $\land$ and \emph{join} $\lor$ as order-preserving maps:
%\begin{align*}
%  \land\;,\lor &:\; \mathcal{L} \times \mathcal{L} \longrightarrow \mathcal{L}.
%\end{align*}
\noindent
The other operations are given as the maps:
\begin{align*}
  \otimes,\;\oplus,\;\to &:\; S \times S\longrightarrow S.
\end{align*}
and form two commutative monoids $\bigl(S,\;\otimes,\;1)$ and $\bigl(S,\;\oplus,\;0)$.
\end{definition}

\noindent
For quantification, we want to allow for different aggregation operations other than infinite meet and join to cover the quantifiers of Logic Tensor Networks \cite{DBLP:journals/ai/BadreddineGSS22}. 
%
\begin{definition}[Aggregated 2CMon-Lat]\label{def:aggregated-2CMon-Lat}
An \emph{aggregated 2CMon-Lat} has a pair of order preserving maps, one pair of maps for each set $X$:
\begin{align*}
 \mathrm{aggr}_X^\forall, \mathrm{aggr}_X^\exists  &:\; \mathcal{L}^X \longrightarrow \mathcal{L}.
\end{align*}
In the case of a complete lattice, $\mathrm{aggr}_X^\forall$ can be chosen as meet $\bigwedge_X$ and $\mathrm{aggr}_X^\exists$ as join $\bigvee_X$.

%\begin{definition}[Complete 2CMon-Lat]\label{def:complete-2CMon-Lat}
%If  $\mathcal{L}$ is complete we obtain the \emph{infinite meet} $\bigwedge$ and the \emph{infinite join} $\bigvee$ as order-preserving maps:
%\begin{align*}
%  \bigwedge,\;\bigvee &:\; \mathcal{P}(\mathcal{L}) \longrightarrow \mathcal{L}.
%\end{align*}
%\end{definition}

\noindent
\paragraph{Categorical generalisation:}
A complete 2CMon-Lat internal to a cartesian closed category $\mathcal{C}$\footnote{Such a category has exponential objects (``function spaces'') $A^B$ and currying, that is, for $f:A\times B\to C$, there is $\Lambda(f):A\to C^B$.} consists of an object $A$ in $\mathcal{C}$, a lattice on A internal to $\mathcal{C}$, morphisms $\oplus,\otimes, \to:A\times A\to A$, $0,1:1_\mathcal{C}\to A$ and for each object $X\in\mathrm{Ob}(\mathcal{C})$ morphisms $\mathrm{aggr}_X^\forall, \mathrm{aggr}_X^\exists:A^X\to A$,  such that the above axioms hold when appropriately interpreted in $\mathcal{C}$\footnote{$1_\mathcal{C}$ is a terminal object.}. %Check the appendix for details.
\ednote{ \textbf{1Fh6}: "Specify what 'internal to' a category means, and what a cartesian closed category is"}
\end{definition}

\subsection{Neurosymbolic frameworks}
\label{subsec:nesy-frameworks}

Given some basic notion of truth $\Omega$, we assume that NeSy systems work on the monadic space of truth values $\mathcal T\Omega $, which is required to be a 2CMon-Lat. If $\mathcal T$ is the identity monad, $\mathcal T\{ 0,1\}$ is just the two-element set $\{ 0,1\}$ of classical truth values. 
If $\mathcal T$ is the distribution or probability monad, $\mathcal T\{ 0,1\}$ is the unit interval $[0,1]$, which can be regarded as the space of probabilistic or fuzzy truth values.

\begin{definition}[NeSy framework]\label{def:nesy-framework}
A \emph{NeSy framework}  $(\mathcal T,\mathcal R)$ consists of  \ednote{ \textbf{3Pt1}: "in Defintion 4, what is the strength of a monad? What is 
Ob C?"}
\begin{enumerate*}
  \item a strong monad $\mathcal T$ with strength $\mathcal S$ on a cartesian closed category $\mathcal C$,\footnote{TODO: explain strength. Note that $\Set$ is a cartesian closed category, and every monad on $\Set$ is strong. We need cartesian closure for the semantics of quantification and computational function symbols.}\ednote{ \textbf{1Fh6}: "Define 'strong monad'"}
  \item an aggregated 2CMon-Lat $\mathcal R$ internal to $\mathcal{C}$ on $\mathcal T\Omega $ for some $\Omega \in \ObC$ of truth values.
\end{enumerate*}

\noindent
Examples are given in Table \ref{tab:basic-nesy-frameworks} and discussed in more detail in section~\ref{sec:prob-monad}.
\begin{table}[h]
\centering
\caption{NeSy Framework Examples}
\label{tab:basic-nesy-frameworks}
\begin{tabular}{@{}llllll@{}}
\toprule
\textbf{Logic/Theory} & \textbf{$\mathcal C$} & \textbf{$\mathcal T$} & \textbf{$\Omega$} & \textbf{$\mathcal T\Omega$} & \textbf{2CMon-Lat} \\ \midrule
Classical                       & $\mathbf{Set}$ & Identity                                        & $\{0,1\}$          & $\{0,1\}$            & Boolean Alg. \\
Three-valued LP                    & $\mathbf{Set}$ & Powerset $ \mathcal{P}_{\neq \emptyset}$                                    & $\{0,1\}$          & $\{0,B,1\}$            & Kleene/Priest Alg.  \\
Classical Fuzzy              & $\mathbf{Set}$ & Identity                                        & $[0,1]$            & $[0,1]$              & BL–Alg. \\
Discrete Probabilistic            & $\mathbf{Set}$ & Distribution $\mathcal D$                       & $\{0,1\}$          & $[0,1]$              &Product BL-Alg. \\
Cont. Probabilistic             & $\mathbf{QBS}$ &Giry $\mathcal G$                               & $\{0,1\}$          & $[0,1]$              &Product BL-Alg. \\
Infinitary $\text{LTN}_p$                     & $\mathbf{QProb}$ & Probability $\mathcal O$                                    & $\{0,1\}$          & $[0,1]$            &Product BL-Alg. \\
\bottomrule
\end{tabular}
\end{table}

\noindent
Note that further examples arise by varying the 2CMon-Lat $\mathcal R$ on $[0,1]$.%, and also check Table~\ref{tab:fuzzy-frameworks} and \ref{tab:distributional-nesy-frameworks} for even more examples, like STL, possibility theory and other fuzzy versions.
\end{definition}



\section{Syntax and Semantics of Monadic ULLER}
\label{sec:syntax-and-semantics}

\subsection{Syntax of First-Order Logic}\label{subsec:fol-syntax}
The ULLER language of \cite{vankriekenULLERUnifiedLanguage2024} features computational function symbols that can be realized e.g.\ by neural networks. In a similar spirit, we here add computational predicate symbols, which are also realized by neural networks, for example in Logic Tensor Networks  \cite{DBLP:journals/ai/BadreddineGSS22}.
\begin{definition}[NeSy System Signature]\label{def:signature}
A \emph{NeSy system signature} $\Sigma$ consists of a set $S$ of {\em sorts}, two disjoint $S^{*}\! {\times}S$-sorted families:
 $\F=(\F_{w,s})_{w\in\! S^{*}\! ,s\in\! S}$ and
$\MF=(\MF_{w,s})_{w\in\! S^{*}\! ,s\in\! S}$ 
of {\em function symbols} and {\em computational function symbols}, and
two disjoint $S^{*}$-sorted families: $\P = (\P_{w})_{w \in S^{*}}$  and $\MP = (\MP_{w})_{w \in S^{*}}$ of {\em predicate symbols} and {\em computational predicate symbols}.
\ednote{ \textbf{1Fh6}: "What does the notation $S^{*}$ mean? Are the families of function symbols confusing? Is there a single function symbol for each combination of sorts?"}

Function symbols with no arguments are called constants ($\mathrm{Const}$), and (computational) predicate symbols with no arguments are called (computational) propositional symbols ($\mathrm{Prps}$ and $\mathrm{MPrps}$ respectively). Function symbols with one argument are called properties $(\mathrm{Prop})$.
\end{definition}
\noindent
Concerning syntax, we largely follow the definitions given in \cite{vankriekenULLERUnifiedLanguage2024}. That is, just like in the original ULLER framework we define our syntax as a context-free grammar. Given a \emph{signature} $\Sigma$ of non-logical symbols and set of variables $\mathrm{V}$, we can define the syntax of first-order logic (FOL) formulas over $\Sigma$ and $\mathrm{V}$ as follows:
\begin{align*}
    &\textbf{Compound Formulas:} \\
    F &::= x := m(T, \ldots, T)(F) &\quad [m \in \mathrm{MF}] \\
    F &::= \forall x:s \ (F) \mid \exists x:s \ (F) \\
    F &::= F \wedge  F \mid F  \vee  F \mid F \to \; F \mid \neg F \mid (F) \\
    &\textbf{Atomic Formulas:} \\
    F &::= M(T, \ldots, T) \mid N         &\quad [M \in \mathrm{MP}, N \in \mathrm{MPrps}] \\
    F &::= P(T, \ldots, T)  \mid R \mid \bot \mid \top         &\quad [P \in \P, R \in \mathrm{Prps}] \\
    &\textbf{Terms:} \\
    T &::= x : s               &\quad [x \in \mathrm{V}, s \in S] \\
    T &::= f(T, \ldots, T) \mid T.\mathsf{prop} \mid c         &\quad [f \in \mathrm{F}, \mathsf{prop} \in \mathrm{Prop}, c \in \mathrm{Const}]
\end{align*}

\subsection{Tarskian Semantics}\label{subsec:tarsk-sem}

\begin{definition}[{$\mathcal{T}$-interpretation of a NeSy system signature}]
\label{def:monadic-model}
Let  $(\mathcal T,\mathcal R)$ be a NeSy framework of a monad on $\mathbf{Set}$ and let \(\Sigma\) be a signature. A $\mathcal T$-interpretation $\mathcal I$ is given by
\begin{itemize}
 \item  a set $\mathcal I(s)$ for every sort $s$, 
 \item a function $\mathcal I(f) : \mathcal I(s_1) \times \ldots \times \mathcal I(s_n) \to \mathcal I(s)$ for every (normal) function symbol $f : s_1, \ldots, s_n \to s$,
 \item a function $\mathcal I(m) : \mathcal I(s_1) \times \ldots \times \mathcal I(s_n) \to \mathcal T(\mathcal I(s))$ for every computational function symbol $m : s_1, \ldots, s_n \to s$,
 \item a function $\mathcal I(P) : \mathcal I(s_1) \times \ldots \times \mathcal I(s_n) \to \Omega$ for every predicate symbol $P : s_1, \ldots, s_n$,
 \item and a function $\mathcal I(M) : \mathcal I(s_1) \times \ldots \times \mathcal I(s_n) \to \mathcal T\Omega$ for every computational predicate symbol $M : s_1, \ldots, s_n$.
\ednote{ \textbf{1Fh6}: "There are two methods for using neural networks (in functions and in predicates), which are handled quite differently."} 
\ednote{ \textbf{1Fh6}: "The original ULLER did not have computational predicate symbols. Do differentiable fuzzy logic behaviours come from computational predicate symbols?"}
 \end{itemize}
In the categorical generalisation, sets are replaced by objects in $\mathcal C$ and functions are replaced by morphisms in $\mathcal C$. Therefore, a \emph{NeSy system} can be defined as a triple $(\mathcal T,\mathcal R,\mathcal I)$, where $(\mathcal T,\mathcal R)$ is a NeSy framework and $\mathcal I$ is a $\mathcal T$-interpretation.
\end{definition}
\ednote{ \textbf{1Fh6}: "Definition 6: The main motivation for the original ULLER was reuse of the same syntactic theory + neural networks. However, the different semantics require different interpretations of computational symbols. Doesn't this reduce reusability?"}

\noindent
In \cite{vankriekenULLERUnifiedLanguage2024}, based on an interpretation, the notion of NeSy system provides a Tarskian inductive definition $\sem{\cdot}$ of the semantics of formulas and thus it implicitly also defines the semantics of the logical symbols. The drawback of this approach is that the Tarskian semantics $\sem{\cdot}$ is inherently tied to the specific interpretation of the NeSy system. We can disentangle matters here, because we first give a semantics of the logical symbols via a NeSy framework, and based on that, the interpretation provides the semantics of the non-logical symbols. Based on this foundation, the inductive definition of the Tarskian semantics $\sem{\cdot}$ needs to be given only once, and is valid across all NeSy frameworks and systems. 


\begin{definition}[Tarskian semantics $\sem{\cdot}$ of formulas]\label{def:Tarskian-semantics} \ednote{ \textbf{3Pt1}: "The categorical generalisation is hard to understand without background in category theory. Possibly, add a quick background section on Category Theory. "}
Given a NeSy framework $(\mathcal T,\mathcal R)$, a \emph{NeSy interpretation} $\mathcal I$ over $(\mathcal T,\mathcal R)$ we can determine the interpretation morphisms:
\begin{align*}
\textbf{Formulas: }\sem{F}_{\mathcal I}: \mathcal{V}_F \to \mathcal T \Omega, \quad \textbf{Terms: }\sem{T}_{\mathcal I}: \mathcal{V}_T \to \mathcal{I}(s_T).
\end{align*}
We define $\mathcal{V}_T:=\prod_{x:t \in \Gamma_T} \mathcal{I}(t)$. Here $\Gamma_T$ is the context of T and $s_T$ is the (unique) sort of the term $T$.  Analogously $\mathcal{V}_F:=\prod_{x:t \in \Gamma_F} \mathcal{I}(t)$.\ednote{ \textbf{1Fh6}: "'$s_T$ is the (unique) sort of the term $T$' how is this derived? How are the $\pi_{T_1,T_2}$ morphisms defined?"} Note that if $T_1$ is a subterm of $T_2$, there is a projection $\pi_{T_1,T_2}: \mathcal{V}_{T_2} \to \mathcal{V}_{T_1}$, and analogously for formulas.
 $\vec{T}$ stands for $T_1,\ldots,T_n$.
Moreover, $\langle\sem{\vec{T}}_i\!\circ\!\pi_i\rangle_i=\langle
        \sem{T_1}\!\circ\!\pi_1,\dots,
        \sem{T_n}\!\circ\!\pi_n
      \rangle$ and $\sem{\vec{T}}=(\sem{T_1},\ldots,\sem{T_n})$.
Also, recall currying in a cartesian closed category, that is, for $f:A\times B\to C$, there is $\Lambda(f):A\to C^B$.
The categorical semantics ensures that all involved and resulting functions %\footnote{More precisely, morphisms need not even be functions.} 
are morphisms in $\mathcal{C}$, i.e.\ are measurable in case that $\mathcal{C}=\Meas$, etc. With a purely set-theoretic semantics, we would need to prove measurability (or other properties) separately for each NeSy framework.

\noindent
That said, besides the general categorical case, %\footnote{Logician's note: We don't differentiate properly between additive/multiplicative connectives and their units for presentation coherent with the NeSy literature, however, this could easily be adapted.} 
for better understandability, we also translate the equations to their meaning in the category of sets.
We work with variable valuations $\nu\in \mathcal{V}_T$ (and $\nu\in \mathcal{V}_F$), noting that elements of $\prod_{x:t \in \Gamma_T} \mathcal{I}(t)$ map variables $x:t$ to values in $\mathcal{I}(t)$. We write $\sem{T}_{\mathcal I,\nu}=\sem{T}_{\mathcal I}(\nu)$ and $\sem{F}_{\mathcal I,\nu}=\sem{F}_{\mathcal I}(\nu)$. That said, we mostly omit $\mathcal I$ and $\nu$ if clear from the context.

\begin{table}[h]
\centering
\caption{Inductive definition of the Tarskian semantics}
\vspace{0.4em}
\label{tab:semantics}
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Syntax} &
\textbf{Categorical Semantics} $\sem{\cdot}_{\mathcal I}$&
\textbf{Set Semantics $\sem{\cdot}_{\mathcal I,\nu}$} \\
\midrule
\multicolumn{3}{@{}l}{\textbf{Terms}}\\ \midrule
$\displaystyle 
\sem{x:s}$ & $\id_{\mathcal I(s)}$ & $\displaystyle \nu(x)$\\

$\displaystyle 
\sem{f(\vec{T})}$ &
$\displaystyle 
\mathcal I(f)\circ\langle \sem{\vec{T}}_i\!\circ\!\pi_i\rangle_i$
&
$\displaystyle
\mathcal I(f)\bigl(\sem{\vec{T}}\bigr)$ \\

$\displaystyle 
\sem{T.\mathsf{prop}}$ &
$\displaystyle 
\mathcal I(\mathsf{prop})\circ\sem{T}$ &
$\displaystyle
\mathcal I(\mathsf{prop})(\sem{T})$ \\

$\displaystyle 
\sem{c}$ & $\mathcal I(c)$ & $\displaystyle\mathcal I(c)$\\ 

\midrule
\multicolumn{3}{@{}l}{\textbf{Atomic formulas}}\\ \midrule
$\displaystyle 
\sem{M(\vec{T})}$ &
$\displaystyle 
\mathcal I(M)\circ\langle \sem{\vec{T}}_i\!\circ\!\pi_i\rangle_i$
&
$\displaystyle
\mathcal I(M)\bigl(\sem{\vec{T}}\bigr)$ \\
$\displaystyle 
\sem{R(\vec{T})}$ &
$\displaystyle 
\eta_\Omega\circ\mathcal I(R)\circ\langle \sem{\vec{T}}_i\!\circ\!\pi_i\rangle_i$
&
$\displaystyle
\eta_\Omega\bigl(\mathcal I(R)(\sem{\vec{T}})\bigr)$ \\
$\displaystyle 
\sem{N}$ & $\mathcal I(N)$ & $\displaystyle\mathcal I(N)$\\
$\displaystyle 
\sem{P}$ & $\eta_\Omega\circ\mathcal I(P)$ & $\displaystyle\eta_\Omega(\mathcal I(P))$\\

\midrule
\multicolumn{3}{@{}l}{\textbf{Compound formulas}}\\ \midrule
$\displaystyle 
\sem{x := m(\vec{T})(F)}$ &
$\displaystyle 
\sem{F}^{*}\!\circ\!\mathcal S\!\circ
\bigl\langle
\pi_{V_{F\setminus x:s}}, \mathcal I(m)\circ\langle \sem{\vec{T}}_i\!\circ\!\pi_i\rangle_i
\bigr\rangle$
&
$\displaystyle
(\lambda a . \sem{F}_{\nu[x\mapsto a]})^{*}\big(I(m)(\sem{\vec{T}})\big)$ \\[4pt]

$\displaystyle 
\sem{\forall x{:}s\,F}$ &
$\displaystyle 
\mathrm{aggr}^\forall_{\mathcal I(s)}\!\circ \Lambda_s(\sem{F}) \circ \pi_{V_{F\setminus x:s}}$
&
$\displaystyle
\mathrm{aggr}^\forall_{\mathcal I(s)}(\lambda a. \sem{F}_{\nu[x\mapsto a]})$ \\[4pt]

$\displaystyle 
\sem{\exists x{:}s\,F}$ &
$\displaystyle 
\mathrm{aggr}^\exists_{\mathcal I(s)}\!\circ \Lambda_s(\sem{F}) \circ \pi_{V_{F\setminus x:s}}$
&
$\displaystyle
\mathrm{aggr}^\exists_{\mathcal I(s)}(\lambda a. \sem{F}_{\nu[x\mapsto a]})$ \\[4pt]

$\displaystyle 
\sem{F\wedge G}$ &
$\displaystyle 
\otimes_{\mathcal R}\!\circ\!
\langle \sem{F}\!\circ\!\pi_F,\sem{G}\!\circ\!\pi_G\rangle$
&
$\displaystyle
\sem{F}\,\otimes_{\mathcal R}\,\sem{G}$ \\[4pt]

$\displaystyle 
\sem{F\vee G}$ &
$\displaystyle 
\oplus_{\mathcal R}\!\circ\!
\langle \sem{F}\!\circ\!\pi_F,\sem{G}\!\circ\!\pi_G\rangle$
&
$\displaystyle
\sem{F}\,\oplus_{\mathcal R}\,\sem{G}$ \\[4pt]

$\displaystyle 
\sem{F\to G}$ &
$\displaystyle 
\to_{\mathcal R}\!\circ
\langle \sem{F}\!\circ\!\pi_F,\sem{G}\!\circ\!\pi_G\rangle$
&
$\displaystyle
\sem{F}\,\to_{\mathcal R}\,\sem{G}$ \\[4pt]

$\displaystyle 
\sem{\neg F}$ &
$\displaystyle 
\sem{F\to \bot}$ &
$\displaystyle
\sem{F}\,\to_{\mathcal R}\,0_\mathcal{R}$ \\[4pt]

$\displaystyle 
\sem{\top}, \sem{\bot}$ & 
$\displaystyle 
1_{\mathcal R}, 0_{\mathcal R}$ & 
$\displaystyle 
1_{\mathcal R}, 0_{\mathcal R}$ \\
\bottomrule
\end{tabular}
\end{table}
\ednote{ \textbf{sLXz}: "This is particularly problematic with the notation and the main results presented on page 6 and Table 2. Please explain the notation to the non-expert. If m is a neural net, what is T and what is F?"}

\end{definition}




\section{Examples of Monad Semantics}\label{sec:prob-monad}

\subsection{Classical and Three-valued Semantics}\label{subsec:classical-sem}

The classical semantics is simply given by the identity monad on the category of sets and the Boolean algebra  %$\mathcal{B}$ 
on $\Omega=\{0,1\}$ which results in classical first-order logic. 

While the classical semantics is deterministic, for modeling argmax, which occurs in the classical semantics of \cite{vankriekenULLERUnifiedLanguage2024}, we will need non-determinism in section~\ref{subsec:nesy-shifts}. 
The (non-empty) powerset monad models non-deterministic computations, cf.\ multialgebras \cite{walicki1994multialgebras}. These result in non-deterministic truth values. The 2CMon-Lat is that for paraconsistent three-valued logic with $\mathcal T\Omega=\{F,T,B\}$, where $B$ stands for \emph{both true and false}. The resulting logic is Priest’s Logic of Paradox (LP)  \cite{priest2008introduction}. While Priest has introduced his logic for dealing with  inconsistent information, the combination with non-deterministic terms arising here quite naturally has not been studied in the literature. 

\subsection{Probabilistic/Distributional Semantics}\label{subsec:prob-sem}

\paragraph{Probabilistic Semantics}\ednote{ \textbf{1Fh6}: "For probabilistic semantics I would expect a weighted model count when using computational predicate symbols (which output distributions over true/false). However, the probabilities seem to be combined using the product algebra - So the probabilistic semantics actually acts as a fuzzy logic when using computational predicate symbols. The only way to introduce weighted model counting is via the computational function symbols. I don't think this would be intuitive for a standard NeSy person."
} The interpretation of a function $f$ of arity $n$ is a \emph{Markov kernel}, which is a measurable map \(X \xrightarrow{q} \mathcal{G}(Y)\) where $\mathcal{G}$ denotes the \emph{Giry monad} on the category of measurable spaces denoted $\Meas$. However, $\Meas$ is not cartesian closed, so we have to generalize to the category $\mathbf{QBS}$\footnote{This category is defined and proven to be cartesian closed in \cite{heunenConvenientCategoryHigherOrder2017} and there it's also proven that $\mathbf{SMeas}$ is a full subcategory of $\mathbf{QBS}$.} of quasi-borel spaces. For simplicity of presentation, we will however mostly work within its full subcategory $\mathbf{SMeas}$ of standard measurable spaces.
We evaluate in the Product BL-Algebra on $[0,1]$ to obtain:\ednote{ \textbf{1Fh6}: "Please define the Product BL-Algebra. (Also typo: Prodcut -> Product)"}
\begin{align}
\sem{x:=m(\vec{T})(F)}
    &:= \int_{a \in \mathcal{I}(s_m)}^{} \sem{F}_{\nu[x\mapsto a]} \ d \rho_m( \; \cdot\mid \vec{T})(a) \label{eq:monad-integral}   \\[8pt]
  \sem{\forall x{:}s\;F}
    &:= \inf_{a \in \mathcal{I}(s)} \sem{F}_{\nu[x\mapsto a]},\quad
  \sem{\exists x{:}s\;F}
    := \sup_{a \in \mathcal{I}(s)} \sem{F}_{\nu[x\mapsto a]} \label{eq:prob-quant}
    \\[4pt]
  \sem{F \wedge G}
    &:= \sem{F} \cdot \sem{G},
\quad
  \sem{F \vee G}
    := \sem{F}  + \sem{G} -  \sem{F}\cdot \sem{G}
    \\[4pt]
  \sem{F \rightarrow G}
    &:= 
          1-\sem{F}+\sem{F}\cdot \sem{G},
    \quad
  \sem{\neg F}
    := 1 - \sem{F}
    \\[2pt]
  \sem{\bot}
    &:= 0, \quad
  \sem{\top}
    := 1.
\end{align}
\ednote{ \textbf{1Fh6}: "Doesn't the product algebra use the Goguen implication instead of the Reichenbach implication? (Eq 4)"}

\paragraph{Infinitary $\text{LTN}_p$ Semantics}

The infinitary $\text{LTN}_p$ semantics is a modification of the probabilistic semantics \ednote{ \textbf{1Fh6}: "The infinitary LTN Semantics is a modification of the probabilistic semantics. This is confusing to me, LTN is a fuzzy logic framework, not a probabilistic one.
"}, which is motivated by replacing the quantifiers in equation~\eqref{eq:prob-quant} with the $p$-means in Stable product real logic of Logic Tensor Networks \cite{DBLP:journals/ai/BadreddineGSS22}.\ednote{ \textbf{sLXz}: "Consider how LTN implements the existential quantifier. This is different from Skolemization and it offers in fact a different kind of fuzzy logic-variation that could be studied by the proposed framework."} The hyperparameter $p$ is usually increased during training, because this moves from mean (tolerant to outliers) towards maximum (logically stricter). We generalize this such that for any sort $s$ we have to provide a probability measure $\rho_s$ on $\mathcal{I}(s)$ to obtain a $p$-means for infinite domains:

\begin{equation}
M_p(a_1,\dots,a_n):=\displaystyle\Bigl(\frac{1}{n}\sum_{i=1}^{n} a_i^{\,p}\Bigr)^{\!1/p}, \quad   
M_{p}(f;\rho_s)
    :=\Bigl(\,\int_{x \in X} f(x)^{p}\,d\rho_s(x)\Bigr)^{\!1/p},
\end{equation}

\noindent
and these extend to\footnote{Here the product is similar to the infinitary product used in ULLER for the semantics of the universal quantifier in  probabilistic semantics. Since that infinitary product is however
not well-defined, we use $M_{0}(f;\rho_s)$, which also works for the infinite case and is p-means in the finite case (for a uniform distribution). If we want to obtain a finite product, we alternatively can iterate conjunction.} $M_0(a_1,\dots,a_n):=\Bigl(\prod_{i=1}^{n} a_i\Bigr)^{\frac{1}{n}}$ and
\(M_{0}(f;\rho_s):=\exp \bigl(\int \ln f\,d\rho_s\bigr)\). For \(p\to\infty\) we recover the supremum.  Take \(X=\{1,\dots,N\}\) with counting measure \(1/N\),
then \( M_{p}(f;\rho_s)\) reduces to $M_p(a_1,\dots,a_n)$ or choose weights \(w_i\) summing up to 1 for \(i=1,\dots,N\) to obtain the weighted $p$-mean. The aggregated 2CMon-Lat is the same as in probabilistic logic, except for the aggregation functions: For a hyperparameter $0 < p< \infty$ of $\text{LTN}_p$, let $\mathrm{aggr}^\exists_{\mathcal I(s)}(f) := M_{p}(f;\rho_s)$ and $\mathrm{aggr}^\forall_{\mathcal I(s)}(f) := 1-M_{p}(\lambda x. f(1-x);\rho_s)$. As a result, equation~\eqref{eq:prob-quant} now becomes:
\begin{align}
  \sem{\exists x{:}s\;F}
    &
    =\Bigl(\,\int_{a\in\mathcal{I}(s)} \bigl(\sem{F}_{\nu[x\mapsto a]}\bigr)^{p}\,d\rho_s\Bigr)^{\!1/p} , &
  \sem{\forall x{:}s\;F}
    &
    =1-\Bigl(\,\int_{a\in\mathcal{I}(s)} \bigl(\sem{F}_{\nu[x\mapsto 1-a]}\bigr)^{p}\,d\rho_s\Bigr)^{\!1/p}
\end{align}

\noindent
It's worth noting that our probability measure $\rho_s$ depend on the sort $s$ of the variable $x$ in the quantifier, in contrast to \cite{slusarzLogicDifferentiableLogics2023}, where the probability measure depends directly on the variable $x$. Instead, we extend the category $\mathbf{QBS}$ to a category $\mathbf{QProb}$ of quasi-Borel spaces equipped with a probability measure\footnote{As defined in \cite{heunenConvenientCategoryHigherOrder2017} [p. 3].} on quasi‑Borel spaces and also extend the Giry monad on $\mathbf{QBS}$ to a monad on $\mathbf{QProb}$.

\paragraph{Distributional Semantics} The Giry monad $\mathcal G$ restricts to the \emph{distribution monad} on $\mathbf{Set}$. This semantics is the probabilistic
semantics of section~\ref{subsec:prob-sem} with $\mathcal G$ replaced by
$\mathcal D$, the Giry
integral collapses to a finite sum:
\[
  \sem{x:=m(\vec{T})(F)}(h) \;=\;
\sum_{u \in \mathcal{I}(s_m)}^{} \sem{F\backslash x:s}(h)(u) \cdot \rho_m( u \mid \vec{T}_h).
\]

\subsection{NeSy Framework Shifts}
\label{subsec:nesy-shifts}


\begin{definition}[NeSy Framework Shift]\label{def:nesy-shift}
For any NeSy framework $(\mathcal{T},\mathcal{R})$, let $\ \mathrm{Intp}((\mathcal{T},\mathcal{R}),\Sigma)$ denote the set of all interpretations over signature $\Sigma$. A \emph{NeSy framework shift} $\gamma : (\mathcal{T},\mathcal{R}) \to (\mathcal{T}',\mathcal{R}')$ between two NeSy frameworks $(\mathcal{T},\mathcal{R})$ and $(\mathcal{T}',\mathcal{R}')$ is a family of functions $\mathrm{Intp}(\gamma)_\Sigma : \mathrm{Intp}((\mathcal{T},\mathcal{R}),\Sigma) \to \mathrm{Intp}((\mathcal{T}',\mathcal{R}'),\Sigma)$ and we normally just write $\gamma(\mathcal{I})$ for $\mathrm{Intp}(\gamma)_\Sigma(\mathcal{I})$.

\end{definition}

\paragraph{Argmax shift: From distributional to non-deterministic semantics}
\label{par:argmax}
For a given distributional interpretation $\mathcal{I}(m)$ of a computational function symbol $m$, we can define a non-deterministic interpretation $\gamma(\mathcal{I})(m)$ of $m$ by defining, where $s_m$ is the sort of $m$:
$$ \gamma(\mathcal{I})(m):= \argmax_{u \in \mathcal{I}(s_m)} \mathcal{I}(m)(u),$$ 
and for a computational predicate symbol $M$ with a projection $\mathrm{pro}: [0,1] \to \{F,T,B\}$:
\[
\gamma(\mathcal{I})(M) :=  \mathrm{pro} \circ \mathcal{I}(M), \qquad
\mathrm{pro}(x) :=
\begin{cases}
  T & \text{if } x > 1/2, \\
  B & \text{if } x = 1/2, \\
  F & \text{if } x < 1/2,
\end{cases}
\]
\noindent
and for all other symbols set $\gamma(\mathcal{I}):= \mathcal{I}$. This definition is \emph{not} possible in the general probabilistic case, because probability measures often return zero on \emph{all} single values. It is also a non-deterministic interpretation since it returns a \emph{set} of values instead of a single value. The resulting semantics is three-valued, as in section~\ref{subsec:classical-sem}. Then, in the practical implementation of ULLER, we can use random sampling (see section~\ref{subsec:sampling}) over a uniform distrubtion (unif)  to obtain a single value from the set of values returned by $\gamma(\mathcal{I})(m)$.
This gives a precise foundation for the use of $\argmax$ in the classical semantics in \cite{vankriekenULLERUnifiedLanguage2024}. 

\paragraph{NeSy shifts diagram}
This $\argmax$ shift is just one example of many possible NeSy shifts, some of which we will display in the following \emph{commutative} diagram, at least the shifts of their computational function symbols \ednote{ \textbf{3Pt1}: "I also found the NeSy shifts hard to understand, perhaps due to missing intuitions early on. "}: % (check the appendix for details):

% https://q.uiver.app/#q=WzAsNixbMCw0LCJcXG1hdGhybXtJZH1fXFxtYXRoYmZ7U2V0fShYKShcXHRleHR7Q2xhc3NpY2FsKX0iXSxbMCwwLCIgXFxtYXRoY2Fse1B9X3tcXG5lcSBcXGVtcHR5c2V0fShYKShcXHRleHR7My12YWx1ZWQpfSJdLFsyLDAsIlxcbWF0aGNhbHtEfShYKShcXHRleHR7RGlzdHJpYnV0aW9uYWwpfSJdLFsxLDIsIlxcbWF0aGNhbHtHfShYKShcXHRleHR7UHJvYmFibGlzdGljKX0iXSxbMiw0LCJcXG1hdGhybXtJZH1fXFxtYXRoYmZ7U2V0fShYKShcXHRleHR7RnV6enkpfSJdLFszLDIsIlxcbWF0aGNhbHtPfShYKShcXHRleHR7TFROKX0iXSxbMCwxLCJcXHtcXGNkb3QgXFx9IiwxLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbMiwzLCIiLDEseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFs0LDIsIlxcZGVsdGEiLDEseyJsYWJlbF9wb3NpdGlvbiI6MzAsInN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn19fV0sWzAsNCwiaWQiLDEseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9LCJoZWFkIjp7Im5hbWUiOiJlcGkifX19XSxbMiwxLCJcXGFyZ21heCIsMSx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6ImVwaSJ9fX1dLFswLDMsIlxcZGVsdGEiLDEseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFsxLDMsIihcXG1hdGhybXt1bmlmfSkiLDEseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFs0LDMsIlxcZGVsdGEiLDEseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFszLDUsIihpZCkiLDEseyJsYWJlbF9wb3NpdGlvbiI6ODAsInN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn0sImhlYWQiOnsibmFtZSI6ImVwaSJ9fX1dXQ==
\ednote{ \textbf{1Fh6}: "I did not understand the NeSy shifts diagram. Where are these proven? What do the different types of arrows mean? What is id and $\delta$?"}
\[\begin{tikzcd}[cramped,sep=scriptsize]
	{ \mathcal{P}_{\neq \emptyset}(X)(\text{3-valued)}} && {\mathcal{D}(X)(\text{Distributional)}} \\
	\\
	& {\mathcal{G}(X)(\text{Probablistic)}} && {\mathcal{O}(X)(\text{LTN)}} \\
	\\
	{\mathrm{Id}_\mathbf{Set}(X)(\text{Classical)}} && {\mathrm{Id}_\mathbf{Set}(X)(\text{Fuzzy)}}
	\arrow["{(\mathrm{unif})}"{description}, hook, from=1-1, to=3-2]
	\arrow["\argmax"{description}, two heads, from=1-3, to=1-1]
	\arrow[hook, from=1-3, to=3-2]
	\arrow["{(id)}"{description, pos=0.8}, hook, two heads, from=3-2, to=3-4]
	\arrow["{\{\cdot \}}"{description}, hook, from=5-1, to=1-1]
	\arrow["\delta"{description}, hook, from=5-1, to=3-2]
	\arrow["id"{description}, hook, two heads, from=5-1, to=5-3]
	\arrow["\delta"{description, pos=0.3}, hook, from=5-3, to=1-3]
	\arrow["\delta"{description}, hook, from=5-3, to=3-2]
\end{tikzcd}\]

\subsection{Sampling}\label{subsec:sampling}
While \cite{vankriekenULLERUnifiedLanguage2024} have introduced a sampling semantics, we think that the semantics should define probabilities, while an implementation can work with e.g.\ Monte Carlo sampling in order to obtain an approximation that is easier to implement (and, in the case of quantification over infinite domains, unavoidable). Hence, we do not discuss sampling semantics here.
But a Monte Carlo convergence theorem can easily be stated and proved. %\ednote{If there is place, state a theorem that sampling for computational function symbols converges to the semantics?} 



\section{Conclusion}

The ULLER language \cite{vankriekenULLERUnifiedLanguage2024} aims at a unifying foundation for neurosymbolic systems. In this paper, we have developed a new semantics for ULLER, based on Moggi's formalisation of computational effects as monads. In contrast to the original semantics, our semantics is truly modular. It is based on a notion of NeSy framework that provides the structure of the computational effects and the space of truth values. This modularity will enable a cleaner, more modular implementation of ULLER in Python \ednote{ \textbf{My3J}: "The paper would benefit from implementation examples or at least sketches demonstrating how the modular semantics could be used in practice, e.g., Python library implementation, and how existing common neurosymbolic systems can be unified under the framework."} and an easier integration of new frameworks, as well as a structured method of translating between different frameworks. Note that the distributional and probabilistic NeSy frameworks will make parameterized interpretations in the sense of \cite{vankriekenULLERUnifiedLanguage2024} differentiable and that this can be integrated by using a category of differentiable manifolds and functions.

Our work suggests an analogy between ULLER's formulas $x:=m(T_1,\dots,T_n)(F)$ and Haskell's do-notation $\textbf{do } x\leftarrow m(T_1,\dots,T_n); F$ for computational effects. Inspired by this analogy, one could extend ULLER to a language with computational terms and formulas that may be nested. \ednote{ \textbf{sLXz}: "More detail should be provided about the last part of the paper which starts to address comparative presentation but not with sufficient clarity."} %\ednote{An if-then-else operator would allow to use these within computational terms. Also, we could allow computational terms $x:=m(T_1,\dots,T_n)(T)$.  Applications?}

\acks{We thank Kai-Uwe Kühnberger for making our collaboration possible and Emile van Krieken for useful discussions. Also a big thanks to my (Daniel's) father for providing me the space-time to work on this paper.}

\newpage

%\
%\ednote{How to number refs and make them clickable in the text?}

\bibliography{references-file, ZOTERO}     %   <-- your .bib file(s) without extension


\newpage
\appendix
\ednote{ \textbf{1Fh6}: "There is a lot of additional material in the appendices, but it is not referenced in the main text. This could help understanding where and when to read it."}

\section{General note on Supplementary Material}

This appendix is supplementary material in the sense of the call for papers. The paper is self-contained and does not depend on the appendix. The appendix contains some more technical details that are not needed for understanding the paper, but which might be useful for the reader who wants to understand the details of the semantics. We also present more sample NeSy frameworks and their shifts.

%Appendix 


\section{Probabilistic Semantics Calculation and Theory}
\label{sec:prob-calc}

\paragraph{Calculation of the interpretation in probabilistic semantics:}
Set $H:= (x:=m(T_1,\dots,T_n)(F))$ and write $\vec{T}:=(T_1,\dots,T_n)$. Fix a valuation $h \in \mathcal{V}_H$. Also write $\vec{T}_h:= (\vec{T}_{h,1},\ldots,\vec{T}_{h,n})$ in which $\vec{T}_{h,i}:=\sem{T_i} \circ \pi_i (h)$ for $i=1,\ldots,n$. Put $\lbrack m(\vec{T}) \rbrack (h) := \mathcal{I}(m)(\vec{T}_{h,1},\ldots,\vec{T}_{h,n})= \rho_m( \; \cdot\mid \vec{T}_h)$, which is a (quasi) probability measure on $\mathcal{I}(s_m)$, where $s_m$ is the sort of the function symbol $m$. Now  calculate:
\begin{align*}
  \sem{x:=m(\vec{T})(F)}(h)
    &\;=\;  \sem{F}^{*} \circ \mathcal{S} \bigl(\mathrm{\pi}_{V_{F\!\backslash x:m}}(h), \; \lbrack m(\vec{T}) \rbrack (h)\bigr) \\
    &\;=\;  \sem{F}^{*}  \bigl( \delta_{\mathrm{\pi}_{V_{F\!\backslash x:m}}(h)} \otimes \lbrack m(\vec{T}) \rbrack (h)\bigr) \\
    &\;=\;  \int_{}^{} \sem{F} \ d \bigl( \delta_{\mathrm{\pi}_{V_{F\!\backslash x:m}}(h)} \otimes \lbrack m(\vec{T}) \rbrack (h)\bigr) \\
    &\;=\;  \int_{u \in \mathcal{I}(s_m)}^{} \sem{F}(\mathrm{\pi}_{V_{F\!\backslash x:m}}(h),u) \ d \bigl(\lbrack m(\vec{T}) \rbrack (h)\bigr)(u) \\
    &\;=\;  \int_{u \in \mathcal{I}(s_m)}^{} \sem{F}(\mathrm{\pi}_{V_{F\!\backslash x:m}}(h),u) \ d \rho_m( \; \cdot\mid \vec{T}_h)(u)
\end{align*}

\noindent
If we further generalize our logic we can also choose a continuous semiring on $[0,1]$ or even a continuous field  (a continuous semiring which is also a field) on $\mathbb{R}$ in the probabilistic semantics. This is in order to closely resemble the canonical measure-theoretical equations underlying probability theory. That is, view $\sem{\_}$ as a probability measure itself and regard F and G as measurable sets of a $\sigma$-algebra on a set $\Chi$.

% and obtain exactly these canonical measure-theoretical equations:

% \begin{align*}
%   \sem{\bigcap_{i=1}^\infty F_i}
%     &:= \inf_i \sem{F_i},
%     \quad
% \sem{\bigcup_{i=1}^\infty F_i}
%     := \sup_i \sem{F_i}
%     \\[4pt]
%   \sem{F\cap G}
%     &:= \min
%         \bigl(
%           \sem{F},\;
%           \sem{G} 
%         \bigr),  \quad 
%   \sem{F\cup G}
%     := \max
%         \bigl(
%           \sem{F},\;
%           \sem{G} 
%         \bigr)
%     \\[4pt]
%   \sem{\bigsqcap_{i=1}^n F_i}
%     &:= \prod_{i=1}^{n}
%           \sem{F_i}, \quad   
%   \sem{\bigsqcup_{i=1}^\infty F_i}
%     := \sum_{i=1}^{\infty}
%           \sem{F_i}
%     \\[4pt]
%   \sem{F \sqcap G}
%     &:= \sem{F}  \cdot \sem{G}, 
%     \quad
%   \sem{F \sqcup G}
%     := \sem{F} + \sem{G}
%     \\[4pt]
%   \sem{F \mid G}
%     &:= 
%           \frac{\sem{F}}{\sem{G}}
%           , \quad
%   \sem{F \backslash G}
%      := 
%           \sem{F} -
%           \sem{G}
%     \\[2pt]
%   \sem{F^c}
%     &:= 1 - \sem{F}
%     \\[2pt]
%   \sem{\emptyset}
%     &:= 0, \quad
%   \sem{\Chi}
%     := 1.
% \end{align*}

% \noindent
% Here $F \backslash G$ denotes the set difference for $F\subseteq G$, $F \mid G$ the conditioning of $F$ on $G$ for $F\subseteq G$, $F^c$ the complement of $F$ in $\Chi$, $F \sqcap G$ the intersection of independent $F$ and $G$, and $F \sqcup G$ the union of disjoint $F$ and $G$, $F \cap\!\slash\!\cup G$ the intersection$\backslash$union of $F$ and $G$ for $F \subseteq G$ or $G \subseteq F$. The notation $\bigcap_{i=1}^\infty F_i$ denotes the intersection of an infinite sequence of sets $F_i$ satisfying $F_{i+1} \subseteq F_{i}$, and $\bigcup_{i=1}^\infty F_i$ the union of an infinite sequence of sets $F_i$ satisfying $F_i \subseteq F_{i+1}$. This can also be generalized to the random variables used in machine learning under the common i.i.d. assumption as mentiond in \cite{vankriekenULLERUnifiedLanguage2024}[p. 9].

\section{Logic Tensor Networks Background}\label{subsec:logic-tensor-background}

\paragraph{Setting} 
Stable product real logic of Logic Tensor Networks \cite{DBLP:journals/ai/BadreddineGSS22} uses $p$-means for finite quantification. The hyperparameter $p$ is usually increased during training, because this moves from mean (tolerant to outliers) towards maximum\footnote{This holds for existential quantification. Universal quantification $\forall$ is defined through $\neg\exists x{:}s\neg$, and then the move is towards minimum.} (logically stricter).
However, since domains are generally infinite, we also need to aggregate infinite many truth–scores
\((x_i)_{i\in I}\subseteq[0,1]\).
The power–mean extends from the finite case
to an \emph{integral} form that is well defined whenever the data are
\(L^{p}\)-integrable. Let \((X,\mathcal A,\rho)\) be a probability space and 
\(f:X\!\to[0,1]\subseteq\mathbb R\) a measurable map with 
\(\displaystyle\int_X f\,d\rho\le 1\).
Because \(0\le f\le 1\), one automatically has 
\(f\in L^{p}(\rho)\) for every real \(p\), so $p$‑means are always defined.
This bounded–by–one assumption reflects the fact that in our logical
reading a truth‑score never exceeds~\(1\). We will concentrate again on the full subcategory $\mathbf{SMeas}$ and extend it to the category $\mathbf{SProb}$ of probability spaces of standard Borel spaces and get an interpretation as:
\begin{itemize}
 \item  a probability space $(X_s, \rho_s)$ for every sort $s$, 
 \item a measure-preserving function $\mathcal I(f)$ for every function symbol $f$,
 \item a measure-preserving function $\mathcal I(m)$ with codomain $\mathcal{O}((X_{s_m}, \rho_{s_m}))$ for every computational function symbol $m$ and its type ${s_m}$,
 \item a measure-preserving function $\mathcal I(R) \bigl(\text{codomain } \{0,1\}\bigr)$ for every predicate symbol $P$,
\item and a measure-preserving function $\mathcal I(M)$ with codomain $\mathcal O (\{0,1\}) \cong [0,1]$ for every computational predicate symbol $M$.
 \end{itemize}

\noindent
Now we are ready to define our probability monad $\mathcal O$ on the category $\mathbf{SProb}$, which basically takes a probability space $(X, \rho)$ and returns the measurable space $(\mathcal{G}(X), \rho^\eta)$, that adds no new information to the probability measure $\rho$. That's exactly what we want, since we we will only use the probability measure $\rho$ to define the semantics of the formulas, and not the derived probability measure $\rho^\eta$:
\begin{proposition}[and definition of the probability monad $\mathcal{O}$]\label{prop:probability-monad}
We can define a probability monad $\mathcal{O}$ as a monad\footnote{Here we use the traditional category theoretical definition of monad as $(\mathcal T,\eta,\mu)$, where $\mu$ is monad multiplication. This is however equivalent to the definition as Kleisli triple.} on the category $\mathbf{SProb}$ with $\eta, \mu$ being the unit and multiplication of the Giry monad $\mathcal{G}$ on $\mathbf{SMeas}$:
\begin{align*}
  \mathcal{O}((X, \rho)) &:= (\mathcal G(X), \rho^\eta),\\
  \rho^\eta &:= B \longmapsto \rho(\eta^{-1}(B)), \text{ for } B\subseteq \mathcal G(X) \text{ measurable},\\
  \eta^\mathcal{O} &:= \eta, \quad \mu^\mathcal{O} := \mu.
\end{align*}
\end{proposition}

\begin{proof}
  We only need to check whether $\eta^\mathcal{O},\mu^\mathcal{O}$ are measure preserving, which follows for the unit by definition:

\[
\eta^{\mathcal{O}} : (X,\rho)\; \longrightarrow\; \bigl(\mathcal{G}(X),\,\rho^{\eta}\bigr)
\]

\[
\rho\bigl((\eta^{\mathcal{O}})^{-1}(B)\bigr)
     \;=\;
  \rho\bigl(\eta^{-1}(B)\bigr)
     \;=\;
  \rho^{\eta}(B).
\]
Now, for the multiplication we have:
\[
\mu^{\mathcal{O}} : \bigl(\mathcal{G}^{2}(X),\,\rho\!\circ\!\eta^{-1}\!\circ\!\eta^{-1}_\mathcal{G}\bigr)
              \;\longrightarrow\;
              \bigl(\mathcal{G}(X),\,\rho\!\circ\!\eta^{-1}\bigr)
\]
since
\[
O^{2}(X)
   \;=\;
O\bigl(\bigl(\mathcal{G}(X),\rho^{\eta}\bigr)\bigr)
   \;=\;
\bigl(\mathcal{G}^{2}(X),\,(\rho^{\eta})^{\eta}\bigr),
\]

\noindent
and that means we can write for any measurable set $A\subseteq \mathcal{G}^2(X)$:
\[
(\rho^{\eta})^{\eta}(A)
  \;=\;
  \rho^{\eta}\bigl(\eta_{\mathcal{G}}^{-1}(A)\bigr)
  \;=\;
  \rho\bigl(\eta^{-1} \circ \eta_{\mathcal{G}}^{-1}(A)\bigr).
\]

\noindent
This means we show the measure-preserving property as follows
\[
\rho\!\circ\!\eta\!\circ\!\eta_{\mathcal{G}}^{-1}
   \bigl(\mu^{-1}(B)\bigr)
   \;=\;
\rho\!\circ\!\eta^{-1}
   \bigl(\eta_{\mathcal{G}}^{-1}(\mu^{-1}(B))\bigr)
   \;=\;
\rho\!\circ\!\eta^{-1}(B),
\]

\noindent
because we know the following fact from the monad laws:
\[
A=\eta_{\mathcal{G}}^{-1}\bigl(\mu^{-1}(B)\bigr)
  \;\Longleftrightarrow\;
  A=\mu\bigl(\eta_{\mathcal{G}}(A)\bigr)=B.
\]

\end{proof}







\section{Possibilistic Semantics and STL}\label{subsec:poss-monad-sem}
Our final goal in this section is to define monads suitable for the semantics of \emph{Possibility Logic} as in \cite{Possibilistic:Dubois1994} and \emph{STL} (Signal Temporal Logic) as in \cite{slusarzLogicDifferentiableLogics2023}. First we expand the distribution monad $\mathcal D$ from example~\ref{ex:dist-monads} to the sub-distribution monad $\mathcal S$ and then use this monad $\mathcal S$ to define a possibility monad $\tilde{\Pi}$, which in turn extends differentiably to a $\text{STL}_\phi$ monad $\tilde{\Pi}_\phi$. These four distributional monads are depicted in Table~\ref{tab:distributional-nesy-frameworks}. The lengthy and technical proofs that these are indeed monads are omitted here, but will be part of a technical report accompanying this paper.

\begin{table}[h]
\centering
\caption{Distributional NeSy Frameworks}
\label{tab:distributional-nesy-frameworks}
\begin{tabular}{@{}llllll@{}}
\toprule
\textbf{Logic/Theory} & \textbf{$\mathcal C$} & \textbf{$\mathcal T$} & \textbf{$\Omega$} & \textbf{$\mathcal T\Omega$} & \textbf{Alg. Struct.} \\ \midrule
Discrete Probabilistic            & $\mathbf{Set}$ & Distribution $\mathcal D$                       & $\{0,1\}$          & $[0,1]$              &Cont. Semirings \\
Intuitionistic Fuzzy            & $\mathbf{Set}$ & Sub-Distribution $\mathcal S$                       & $\{0,1\}$          & $\Delta_1$              &Cont. Semirings \\
Possibility                     & $\mathbf{Set}$ & Possibility Monad $\tilde{\Pi}$                                    & $\{0,1\}$          & $[-1,1]$            & $\min\slash\max$ Alg.  \\
$\text{STL}_\phi$                      & $\mathbf{Set}$ & $\text{STL}_\phi$ Monad $\tilde{\Pi}_\phi$                                    & $\{0,1\}$          & $[-\infty,\infty]$            & $\min\slash\max$ Alg.  \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Possibilistic Semantics}

\subsubsection{Sub-distribution Monad}
The sub-distribution monad $\mathcal S$ is similar to the distribution monad $\mathcal D$ but it allows for finitely supported measures that do not sum up to 1, that means:

\begin{definition}[Sub-Distribution Monad $\mathcal S$]\label{def:sub-monad}
\[
  \mathcal S X := \Bigl\{\,
     p:X\to[0,1]\;\Bigm|\;
     \text{$p$ has finite support and }\sum_{x\in X}p(x)\leq1
   \Bigr\},
\]
\[
  \eta_X(x):=\delta_x, \delta_x(y)=\left\{\begin{array}{l}1,\ x=y\\0,\ x\not=y\end{array}\right.\ 
  f^{*}(p)(y):=\sum_{x\in X}\!p(x)f(x)(y)
  \quad\bigl(f:X\!\to\!\mathcal S Y,\;p\in\mathcal S X\bigr).
\]
\end{definition}


\begin{lemma}\label{lem:M01-is-simplex}
For the two-element set $\Omega=\{0,1\}$ the sub-distribution monad yields
\[
  \mathcal S \Omega
    \;\cong\;
    \Delta_1
    \;:=\;
    \bigl\{(p_0,p_1)\in[0,1]^2 \mid p_0+p_1\le 1\bigr\}.
\]
Explicitly, the bijection
$\varphi\colon\mathcal S\Omega \longrightarrow\Delta_1$ is
$\varphi(p)=(p(0),p(1))$ and its inverse sends a pair
$(a,b)\in\Delta_1$ to the finitely supported measure
\(p_{a,b}:=\!a\,\delta_0+b\,\delta_1\).
\end{lemma}

\begin{proof}
A finitely supported \(\mathcal S\)-measure on a finite set is entirely
determined by its values on the points of the set.  Hence
$p\mapsto(p(0),p(1))$ is injective.
Because $p(\Omega)=p(0)+p(1)\le1$, its image lies in
\(\Delta_1\).  Conversely, every $(a,b)\in\Delta_1$ defines a
measure $p_{a,b}$ with total mass $a+b\le1$ and finite support
$\{0,1\}$.  Thus $\varphi$ is a bijection.
\end{proof}

\noindent
Therefore, as already seen in Table~\ref{tab:distributional-nesy-frameworks}, the sub-distribution monad $\mathcal S$ and its so-called "Intuitionistic Fuzzy Set Logic"\footnote{As found in \cite{atanassovIntuitionisticFuzzySets1986}.} work on the truth value space $\Delta_1$, which we want to \emph{avoid} because it is two-dimensional and not easily relatable to the classical truth values $\{0,1\}$ and fuzzy truth values $[0,1]$. Instead, we want to project these down to the one-dimensional space $[-1,1]$ of possibility values, which we will characterize as the space of truth values of \emph{Possibility Logic} as in \cite{Possibilistic:Dubois1994}.

\subsubsection{Possibility Monad $\tilde{\Pi}$}\label{subsec:poss-monad}

\paragraph{Intuition} The intuition behind the possibility monad $\tilde{\Pi}$ that we will define is the following: Take the triangle $\mathcal S \Omega \cong \Delta_1$ of sub-distributions inside the square and first project it down to the $\mathsf L$ shaped axes as in the following picture:

% https://q.uiver.app/#q=WzAsMTQsWzAsMCwiKDAsMSkiXSxbMCw0LCIoMCwwKSJdLFs0LDQsIigxLDApIl0sWzQsMCwiKDEsMSkiXSxbMSwxXSxbMCwxXSxbMiwyXSxbMCwyXSxbMiw0XSxbMyw0XSxbMywzXSxbMSwzXSxbMCwzXSxbMSw0XSxbMCwxLCIiLDAseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzEsMiwiIiwwLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFswLDIsIiIsMix7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbNCw1LCIiLDAseyJzaG9ydGVuIjp7InNvdXJjZSI6MTB9fV0sWzYsN10sWzEwLDldLFsxMSwxMl0sWzExLDEzXSxbNiw4XSxbMTYsMSwiIiwxLHsibGV2ZWwiOjF9XV0=
\[\begin{tikzcd}[cramped,sep=scriptsize]
	{(0,1)} &&&& {(1,1)} \\
	{} & {} \\
	{} && {} \\
	{} & {} && {} \\
	{(0,0)} & {} & {} & {} & {(1,0)}
	\arrow[no head, from=1-1, to=5-1]
	\arrow[""{name=0, anchor=center, inner sep=0}, no head, from=1-1, to=5-5]
	\arrow[shorten <=2pt, from=2-2, to=2-1]
	\arrow[from=3-3, to=3-1]
	\arrow[from=3-3, to=5-3]
	\arrow[from=4-2, to=4-1]
	\arrow[from=4-2, to=5-2]
	\arrow[from=4-4, to=5-4]
	\arrow[no head, from=5-1, to=5-5]
	\arrow[from=0, to=5-1]
\end{tikzcd}\]

\noindent
And then take the resulting $\mathsf L$ shape and project it down to the line $[-1,1]$ as in:

% https://q.uiver.app/#q=WzAsMTgsWzQsMCwiKDAsMSkiXSxbNCw0LCIoMCwwKSJdLFs4LDQsIigxLDApIl0sWzQsMV0sWzQsMl0sWzYsNF0sWzcsNF0sWzQsM10sWzUsNF0sWzgsNiwiMSJdLFs0LDYsIjAiXSxbMCw2LCItMSJdLFsxLDZdLFsyLDZdLFs1LDZdLFs2LDZdLFs3LDZdLFszLDZdLFswLDEsIiIsMCx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbMSwyLCIiLDAseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzAsMTFdLFsxLDEwXSxbMiw5XSxbMywxMl0sWzQsMTNdLFs4LDE0XSxbNSwxNV0sWzYsMTZdLFs3LDE3XSxbMTEsMTAsIiIsMSx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbMTAsOSwiIiwxLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dXQ==
\[\begin{tikzcd}[cramped,sep=small]
	&&&& {(0,1)} \\
	&&&& {} \\
	&&&& {} \\
	&&&& {} \\
	&&&& {(0,0)} & {} & {} & {} & {(1,0)} \\
	\\
	{-1} & {} & {} & {} & 0 & {} & {} & {} & 1
	\arrow[no head, from=1-5, to=5-5]
	\arrow[from=1-5, to=7-1]
	\arrow[from=2-5, to=7-2]
	\arrow[from=3-5, to=7-3]
	\arrow[from=4-5, to=7-4]
	\arrow[no head, from=5-5, to=5-9]
	\arrow[from=5-5, to=7-5]
	\arrow[from=5-6, to=7-6]
	\arrow[from=5-7, to=7-7]
	\arrow[from=5-8, to=7-8]
	\arrow[from=5-9, to=7-9]
	\arrow[no head, from=7-1, to=7-5]
	\arrow[no head, from=7-5, to=7-9]
\end{tikzcd}\]

\noindent
The above pictures can be relabeled in order to match the definitions of the possibility of truth $\Pi(U)$ and the possibility of falsity $\Pi(U^c)$ of an event $U$\footnote{As for example in as for example in \cite{Possibilistic:Dubois1994} [Example 4].}:

% https://q.uiver.app/#q=WzAsNCxbMCw2LCIoMCwwKSJdLFs2LDYsIigxLDApIl0sWzAsMCwiKDAsMSkiXSxbNiwwLCIoMSwxKSJdLFsxLDMsIlxcUGkoVSkiLDJdLFsyLDMsIlxcUGkoVV5jKSJdXQ==
\[\begin{tikzcd}[cramped,sep=small]
	{(0,1)} &&&&&& {(1,1)} \\
	\\
	\\
	\\
	\\
	\\
	{(0,0)} &&&&&& {(1,0)}
	\arrow["{\Pi(U^c)}", from=1-1, to=1-7]
	\arrow["{\Pi(U)}"', from=7-7, to=1-7]
\end{tikzcd}\]

\noindent
In this, a tuple $(a,b) \in \Delta_1$ is given by the values of $(\Pi(U^c),\Pi(U))$. Also, the necessity of an event is defined as $N(U):= 1 - \Pi(U^c)$. Only values inside, or adjacent to the two arrows are obtained, which follows from the definition of possibility measure. In order to make this coherent with the projection picture and also compatible with fuzzy logic in which $[0,1]$ are degrees of \emph{truth} and with STL in which $[0,\infty]$ are degrees of \emph{truth} and $[-\infty,0]$ are degrees of \emph{falsity}, we look at it the following way. The necessity of truth $N(U)$ is interpreted as a degree of \emph{truth} in $[0,1]$ and the \emph{impossibility} of truth $1-\Pi(U)$ is interpreted as a degree of \emph{falsity} in $[-1,0]$. This gives the following picture of values for $(N(U),1-\Pi(U))$:

% https://q.uiver.app/#q=WzAsMTMsWzAsNiwiKDAsMCkiXSxbNiw2LCIoMSwwKSJdLFswLDAsIigwLDEpIl0sWzYsMCwiKDEsMSkiXSxbOCwzLCItMSJdLFsxMiwzLCIwIl0sWzE2LDMsIjEiXSxbMTAsM10sWzExLDNdLFsxMywzXSxbMTQsM10sWzksM10sWzE1LDNdLFswLDIsIjEtXFxQaShVKSJdLFs1LDQsIi0oMS1cXFBpKFUpKSIsMl0sWzUsNiwiTihVKSJdLFswLDEsIk4oVSkiLDJdXQ==
\[\begin{tikzcd}[cramped,sep=small]
	{(0,1)} &&&&&& {(1,1)} \\
	\\
	\\
	&&&&&&&& {-1} & {} & {} & {} & 0 & {} & {} & {} & 1 \\
	\\
	\\
	{(0,0)} &&&&&& {(1,0)}
	\arrow["{-(1-\Pi(U))}"', from=4-13, to=4-9]
	\arrow["{N(U)}", from=4-13, to=4-17]
	\arrow["{1-\Pi(U)}", from=7-1, to=1-1]
	\arrow["{N(U)}"', from=7-1, to=7-7]
\end{tikzcd}\]

\paragraph{Projecting the $\mathsf L$ onto the real line}
Let  
\[
\mathsf L
   \;:=\;
   \bigl\{(a,0)\mid 0\le a\le1\bigr\}
   \;\cup\;
   \bigl\{(0,b)\mid 0\le b\le1\bigr\}
   \;\subseteq\;\Delta_1
\]
be the $L$–shaped subset of~\(\Delta_1\) that runs along the two coordinate
axes.
Define the (piece wise linear) \emph{projection}
\[
  \varphi:\mathsf L\longrightarrow[-1,1],\qquad
  \varphi(a,0):=a,\qquad          %  right-hand leg
  \varphi(0,b):=-\,b              %  left-hand leg
  \quad(0\le a,b\le1).
\]
Hence
\[
  \varphi(0,1)=-1,\qquad
  \varphi(0,0)=0,\qquad
  \varphi(1,0)=1,
\]
so \(\varphi\) folds the two legs of~\(\mathsf L\) onto the interval
\([-1,1]\) in a continuous, order-preserving way.

\paragraph{Min–max algebra on \(\boldsymbol{[-1,1]}\)}
Define the 2CMon-Lat $\mathcal{R}$ as \emph{idempotent commutative semiring} (a min–max algebra):
\[
  S\;:=\;[-1,1],\qquad
  x \otimes_\mathcal{R} y\;:=\;\max\{x,y\},\qquad
  x \oplus_\mathcal{R} y\;:=\;\min\{x,y\},
\]
\[
  0_\mathcal{R}:=-1,\qquad  1_\mathcal{R}:=1.
\]

\paragraph{Back-translation to possibility values}
For every event \(U\) write
\[
  n:=N(U)\in[0,1], \qquad
  \vartheta:=-\bigl(1-\Pi(U)\bigr)\in[-1,0].
\]
Because \((n,\vartheta)\in\mathsf L\), their projection
\(\varphi(n,\vartheta)\in[-1,1]\) is exactly the element on which the
algebra above acts.  
The ordering
\[
  -1\;<\;\cdots\;<\;0\;<\;\cdots\;<\;1
\]
coincides with the intuitive scale  
“certainly false $\;\to\;$ no information $\;\to\;$ certainly true’’,
so \(\oplus_\mathcal{R}\) picks the \emph{more plausible} value and
\(\otimes_\mathcal{R}\) the \emph{less plausible} one—just as the usual
\(\max/\min\) rules of possibility theory. 

Until now we have only worked in the truth value space $[-1,1]$ and explained that we want our monad $\tilde{\Pi}$ to send basic truth values $\Omega=\{0,1\}$ to possibility values $\tilde{\Pi}(\Omega) \cong \mathsf L \cong [-1,1]$. In order to formulate a monad however we need to specify what our monad does with arbitrary sets $X$. The following definition does exactly that, while preserving the above intuition that $\tilde{\Pi}(\Omega) \cong \mathsf L \cong [-1,1]$:


\begin{definition}[Possibility Monad $\tilde{\Pi}$]\label{def:poss-monad}
$\tilde{\Pi}$ is defined as follows for sets \(X\):
\[
A_p := \argmax(p(x)), \qquad
\tilde{\pi}(p):= \max(p)\,\delta_{A_p},
\]
\[
  \tilde{\Pi} (X) := \bigl\{ \tilde{\pi}(p)|\;
     p\in \mathcal S(X): \vert A_p \vert =1
   \bigr\} \cup \bigl\{0\bigr\} \subseteq \mathcal S X,
\]
\[
  \eta_X(x):=\delta_x, \qquad
  k^{*}(\tilde{\pi}(p)):= \tilde{\pi}\bigl(\max(p)k(A_p)\bigr).
\]
\end{definition}


\subsubsection{$\text{STL}_\phi$ Monad}\label{subsec:STL-sem}

\begin{table}[h]
\centering
\caption{Smooth embeddings $\phi:[-1,1]\to\overline{\mathbb R}$}
\label{tab:smooth-embeddings}
\renewcommand{\arraystretch}{1.15}
\begin{tabular}{@{}lll@{}}
\toprule
name & formula $\phi(x)$ & inverse $\phi^{-1}(y)$\\
\midrule
scaled tangent &
$\displaystyle \tan\!\bigl(\tfrac{\pi}{2}x\bigr)$ &
$\displaystyle \tfrac{2}{\pi}\arctan y$\\[8pt]
logit &
$\displaystyle \ln\!\frac{1+x}{1-x}$ &
$\displaystyle \frac{e^{y}-1}{e^{y}+1}$\\[8pt]
$\operatorname{artanh}$ &
$\displaystyle \operatorname{artanh}(x)$ &
$\displaystyle \tanh y$\\[8pt]
rational blow--up &
$\displaystyle \dfrac{x}{1-x^{2}}$ &
$\displaystyle \dfrac{y}{1+\sqrt{1+y^{2}}}$\\[12pt]
arcsine–tan &
$\displaystyle \dfrac{x}{\sqrt{1-x^{2}}}$ &
$\displaystyle \dfrac{y}{\sqrt{1+y^{2}}}$\\[12pt]
\bottomrule
\end{tabular}
\end{table}

\noindent
In STL we work in values $\in \overline{\mathbb R}$ such that gradient–based
optimization treats truth values just like network activations.
In order to achieve this, map the just defined possibility scores $t\in[-1,1]$
to values $\phi(t)\in \overline{\mathbb R}$ with
any smooth, strictly monotone, \emph{odd} diffeomorphism $\phi:(-1,1)\longrightarrow\mathbb R$ satisfying:
\begin{align*}
  & \phi(0)=0,
  && \phi(-x)=-\phi(x), \\
  & \phi(x)>0\text{ for } x>0, 
  && \phi(x)>\phi(y)\text{ for } x>y, \\
  & \lim_{x\to-1^{+}}\!\phi(x)=-\infty,
  && \lim_{x\to 1^{-}}\!\phi(x)=\infty.
\end{align*}

\noindent
Table~\ref{tab:smooth-embeddings} lists several classical choices, $\tanh$ is also used in \cite{slusarzLogicDifferentiableLogics2023} [p. 8]. The choice of $\phi$ depends on the application and the desired properties of the resulting logic. 

\paragraph{Intuition}
We basically do exactly the same projections as before, only that everything is drawn out from the beginng by the smooth diffeomorphism $\phi$ to the extended real line $\overline{\mathbb R}$. That means our triangle $\Delta_1$ is drawn out in two-dimensional space to an infinite one, then we project to an infinite $\mathsf L$ of axes, and then we project to the extended real line $\overline{\mathbb R}$ as in:

% https://q.uiver.app/#q=WzAsMTgsWzQsMCwiKDAsXFxpbmZ0eSkiXSxbNCw0LCIoMCwwKSJdLFs4LDQsIihcXGluZnR5LDApIl0sWzQsMSwiLi4uIl0sWzQsMl0sWzYsNF0sWzcsNCwiLi4uIl0sWzQsM10sWzUsNF0sWzgsNiwiK1xcaW5mdHkiXSxbNCw2LCIwIl0sWzAsNiwiLVxcaW5mdHkiXSxbMSw2LCIuLi4iXSxbMiw2XSxbNSw2XSxbNiw2XSxbNyw2LCIuLi4iXSxbMyw2XSxbMCwxMV0sWzEsMTBdLFsyLDldLFszLDEyXSxbNCwxM10sWzgsMTRdLFs1LDE1XSxbNiwxNl0sWzcsMTddLFsxMiwxMCwiIiwxLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFsxMiwxMSwiIiwxLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFsxMCwxNiwiIiwxLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFsxNiw5LCIiLDEseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzEsNiwiIiwwLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFs2LDIsIiIsMCx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbMywxLCIiLDAseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzMsMCwiIiwwLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dXQ==
\[\begin{tikzcd}[cramped,sep=scriptsize]
	&&&& {(0,\infty)} \\
	&&&& {...} \\
	&&&& {} \\
	&&&& {} \\
	&&&& {(0,0)} & {} & {} & {...} & {(\infty,0)} \\
	\\
	{-\infty} & {...} & {} & {} & 0 & {} & {} & {...} & {+\infty}
	\arrow[from=1-5, to=7-1]
	\arrow[no head, from=2-5, to=1-5]
	\arrow[no head, from=2-5, to=5-5]
	\arrow[from=2-5, to=7-2]
	\arrow[from=3-5, to=7-3]
	\arrow[from=4-5, to=7-4]
	\arrow[no head, from=5-5, to=5-8]
	\arrow[from=5-5, to=7-5]
	\arrow[from=5-6, to=7-6]
	\arrow[from=5-7, to=7-7]
	\arrow[no head, from=5-8, to=5-9]
	\arrow[from=5-8, to=7-8]
	\arrow[from=5-9, to=7-9]
	\arrow[no head, from=7-2, to=7-1]
	\arrow[no head, from=7-2, to=7-5]
	\arrow[no head, from=7-5, to=7-8]
	\arrow[no head, from=7-8, to=7-9]
\end{tikzcd}\]

\begin{definition}[$\text{STL}_\phi$ Monad $\tilde{\Pi}_\phi$]\label{def:STL-monad}
$\tilde{\Pi}_\phi$ is defined for sets \(X\) as, with $\infty\cdot0:=0:$

\[
  \tilde{\Pi}_\phi (X) := \bigl\{ \tilde{\pi}(\phi \circ p)|\;
     p\in \mathcal S(X): \vert A_p \vert =1
   \bigr\} \cup \bigl\{0\bigr\} \subseteq \mathcal S X,
\]

\[
  \eta_X(x):=\delta_x, \qquad
  k^{*}(\tilde{\pi}(\phi \circ p)):= \tilde{\pi}\bigl(\max(\phi \circ p)k(A_p)\bigr).
\]
\end{definition}


\subsubsection{Expanded NeSy shifts diagram}
\noindent
Having properly defined the Possibility and $\text{STL}_\phi$ monads, we can now add them to our NeSy shifts diagram again. Note that the descriptions in parentheses are only for the case of $X$ being finite and $\pi$ means the projection as described in \ref{subsec:poss-monad}:

% https://q.uiver.app/#q=WzAsOCxbMCw2LCIgXFx7MCwxXFx9IFxcdGV4dHsgKENsYXNzaWNhbCl9Il0sWzAsMiwiIFxcezAsIDEvMiwxXFx9IFxcdGV4dHsgKDMtVmFsdWVkKX0iXSxbMiwyLCIgWzAsMV0gXFx0ZXh0eyAoRGlzdHJpYi4pfSJdLFsxLDQsIiBbMCwxXSBcXHRleHR7IChQcm9iYWIuKX0iXSxbMSwwLCJbLTEsMV0gXFx0ZXh0eyAoUG9zc2liaWwuKX0iXSxbNCwwLCJbLVxcaW5mdHksXFxpbmZ0eV0gXFwgXFx0ZXh0e1NUTH1fXFxwaGkiXSxbMiw2LCIgWzAsMV0gXFx0ZXh0eyAoRnV6enkpfSJdLFs0LDQsIiBbMCwxXSBcXHRleHR7IChMVE4pfSJdLFswLDEsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn19fV0sWzIsMywiaWQiLDEseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9LCJoZWFkIjp7Im5hbWUiOiJlcGkifX19XSxbNiwyLCJpZCIsMSx7ImxhYmVsX3Bvc2l0aW9uIjo3MCwic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifSwiaGVhZCI6eyJuYW1lIjoiZXBpIn19fV0sWzAsNiwiIiwyLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbMiwxLCJcXG1hdGhybXtwcm99IiwxLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoiZXBpIn19fV0sWzQsMSwiLTEgXFxtYXBzdG8wIiwxLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoiZXBpIn19fV0sWzQsNSwiXFxwaGkiLDEseyJsYWJlbF9wb3NpdGlvbiI6NzAsInN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn0sImhlYWQiOnsibmFtZSI6ImVwaSJ9fX1dLFsyLDQsIjAgXFxtYXBzdG8gLTEiLDEseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFswLDMsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn19fV0sWzEsMywiIiwwLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbNiwzLCJpZCIsMSx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn0sImhlYWQiOnsibmFtZSI6ImVwaSJ9fX1dLFszLDcsImlkIiwxLHsibGFiZWxfcG9zaXRpb24iOjcwLCJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9LCJoZWFkIjp7Im5hbWUiOiJlcGkifX19XV0=
\[\begin{tikzcd}[cramped,sep=scriptsize]
	& {[-1,1] \text{ (Possibil.)}} &&& {[-\infty,\infty] \ \text{STL}_\phi} \\
	\\
	{ \{0, 1/2,1\} \text{ (3-Valued)}} && { [0,1] \text{ (Distrib.)}} \\
	\\
	& { [0,1] \text{ (Probab.)}} &&& { [0,1] \text{ (LTN)}} \\
	\\
	{ \{0,1\} \text{ (Classical)}} && { [0,1] \text{ (Fuzzy)}}
	\arrow["\phi"{description, pos=0.7}, hook, two heads, from=1-2, to=1-5]
	\arrow["{-1 \mapsto0}"{description}, two heads, from=1-2, to=3-1]
	\arrow[hook, from=3-1, to=5-2]
	\arrow["{0 \mapsto -1}"{description}, hook, from=3-3, to=1-2]
	\arrow["{\mathrm{pro}}"{description}, two heads, from=3-3, to=3-1]
	\arrow["id"{description}, hook, two heads, from=3-3, to=5-2]
	\arrow["id"{description, pos=0.7}, hook, two heads, from=5-2, to=5-5]
	\arrow[hook, from=7-1, to=3-1]
	\arrow[hook, from=7-1, to=5-2]
	\arrow[hook, from=7-1, to=7-3]
	\arrow["id"{description, pos=0.7}, hook, two heads, from=7-3, to=3-3]
	\arrow["id"{description}, hook, two heads, from=7-3, to=5-2]
\end{tikzcd}\]

% https://q.uiver.app/#q=WzAsOCxbMCw2LCJcXG1hdGhybXtJZH1fXFxtYXRoYmZ7U2V0fShYKSJdLFswLDIsIiBcXG1hdGhjYWx7UH1fe1xcbmVxIFxcZW1wdHlzZXR9KFgpIl0sWzQsMiwiXFxtYXRoY2Fse0R9KFgpIl0sWzIsNCwiXFxtYXRoY2Fse0d9IChYKSJdLFsyLDAsIlxcdGlsZGV7XFxQaX0oWCkiXSxbNiwwLCJcXHRpbGRle1xcUGl9X1xccGhpKFgpIl0sWzQsNiwiXFxtYXRocm17SWR9X1xcbWF0aGJme1NldH0oWCkiXSxbNiw0LCJcXG1hdGhjYWx7T30oWCkiXSxbMCwxLCJcXHtcXGNkb3QgXFx9IiwxLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbMiwzLCIiLDEseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFs2LDIsIlxcZGVsdGEiLDEseyJsYWJlbF9wb3NpdGlvbiI6MzAsInN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn19fV0sWzAsNiwiaWQiLDEseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9LCJoZWFkIjp7Im5hbWUiOiJlcGkifX19XSxbMiwxLCJcXGFyZ21heCIsMSx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6ImVwaSJ9fX1dLFs0LDEsIlxcYXJnbWF4IiwxLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoiZXBpIn19fV0sWzQsNSwiXFxwaGkiLDEseyJsYWJlbF9wb3NpdGlvbiI6NzAsInN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn0sImhlYWQiOnsibmFtZSI6ImVwaSJ9fX1dLFsyLDQsIlxcdmFycGhpIFxcY2lyYyBcXHBpIiwxXSxbMCwzLCJcXGRlbHRhIiwxLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbMSwzLCIoXFxtYXRocm17dW5pZn0pIiwxLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbNiwzLCJcXGRlbHRhIiwxLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbMyw3LCIoaWQpIiwxLHsibGFiZWxfcG9zaXRpb24iOjcwLCJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9LCJoZWFkIjp7Im5hbWUiOiJlcGkifX19XV0=
\[\begin{tikzcd}[cramped]
	&& {\tilde{\Pi}(X)} &&&& {\tilde{\Pi}_\phi(X)} \\
	\\
	{ \mathcal{P}_{\neq \emptyset}(X)} &&&& {\mathcal{D}(X)} \\
	\\
	&& {\mathcal{G} (X)} &&&& {\mathcal{O}(X)} \\
	\\
	{\mathrm{Id}_\mathbf{Set}(X)} &&&& {\mathrm{Id}_\mathbf{Set}(X)}
	\arrow["\phi"{description, pos=0.7}, hook, two heads, from=1-3, to=1-7]
	\arrow["\argmax"{description}, two heads, from=1-3, to=3-1]
	\arrow["{(\mathrm{unif})}"{description}, hook, from=3-1, to=5-3]
	\arrow["{\varphi \circ \pi}"{description}, from=3-5, to=1-3]
	\arrow["\argmax"{description}, two heads, from=3-5, to=3-1]
	\arrow[hook, from=3-5, to=5-3]
	\arrow["{(id)}"{description, pos=0.7}, hook, two heads, from=5-3, to=5-7]
	\arrow["{\{\cdot \}}"{description}, hook, from=7-1, to=3-1]
	\arrow["\delta"{description}, hook, from=7-1, to=5-3]
	\arrow["id"{description}, hook, two heads, from=7-1, to=7-5]
	\arrow["\delta"{description, pos=0.3}, hook, from=7-5, to=3-5]
	\arrow["\delta"{description}, hook, from=7-5, to=5-3]
\end{tikzcd}\]




\section{Fuzzy Semantics with Computational Functions}\label{subsec:cont-fuzzy-sem}

In the original ULLER paper, the fuzzy semantics of computational function symbols were introduced to relate closely to fuzzy and differentiable logics and to support the interpretation of fuzzy or differentiable predicates. In our setting those predicates are already interpreted directly in a fuzzy or differentiable manner, so this extra layer is unnecessary. Moreover, the combined use of a t-norm and a t-conorm is not actually exploited in that correspondence and therefore lacks a clear motivation. We instead propose an alternative, monadic definition that also works in the continuous setting, which was previously omitted. The details remain to be elaborated; what follows is a sketch of the underlying idea.


We will define two new monads in addition to the already mentioned identity monad for the Classical Fuzzy semantics given in Table~\ref{tab:basic-nesy-frameworks}.

\begin{table}[h]
\centering
\caption{Fuzzy NeSy Frameworks}
\label{tab:fuzzy-frameworks}
\begin{tabular}{@{}llllll@{}}
\toprule
\textbf{Logic/Theory} & \textbf{$\mathcal C$} & \textbf{$\mathcal T$} & \textbf{$\Omega$} & \textbf{$\mathcal T\Omega$} & \textbf{Alg. Struct.} \\ \midrule
Classical Fuzzy              & $\mathbf{Set}$ & Identity                                        & $[0,1]$            & $[0,1]$              & BL–Alg. \\
Discrete $\oplus$-Fuzzy              & $\mathbf{Set}$ & $\oplus$-Distribution $\mathcal D_{\oplus}$                                           & $\{0,1\}$            & $\oplus_1$              & BL–Alg. \\
Continuous $\oplus$-Fuzzy              & $\mathbf{QBS}$ & $\oplus$-Giry $\mathcal G_{\oplus}$                                        & $\{0,1\}$            & $\oplus_1$              & BL–Alg. \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Pseudo Giry monad}\label{subsec:pseudo-giry}

\begin{definition}[$(\hat{+},\hat{\cdot})$-Giry monad]\label{def:pseudo-giry}
The $(\hat{+},\hat{\cdot})$-\emph{Giry monad} $\mathcal{G}_{(\hat{+},\hat{\cdot})}$ or pseudo-Giry monad with respect to the pseudo-multiplication $\hat{\cdot}$ and pseudo-addition $\hat{+}$ is defined to be a monad on the category of quasi-borel spaces $\mathbf{QBS}$. And yet, we only will talk about its restriction on the full subcategory\footnote{See \cite{heunenConvenientCategoryHigherOrder2017} for a proof that this forms indeed a full subcategory.} $\mathbf{SMeas}$ of standard measurable spaces to present it more understandably. The pseudo-Giry monad is defined as follows:
\begin{align*}
  \mathcal{G}_{(\hat{+},\hat{\cdot})}(X) &:= \{\rho: X \to [0,1] \mid \rho \text{ is $\hat{+}$-measurable,} \int_X^{\hat{+},\hat{\cdot}} \rho(x) \; dx = 1\} \\
  \mathcal{G}_{(\hat{+},\hat{\cdot})}(f) &:= \bigl(\rho \mapsto \rho \circ f \bigr)
\end{align*}
\end{definition}

\noindent
Instead of taking of a t-norm and t-conorm pair we have taken a pair of pseudo-addition $\hat{+}$ and pseudo-multiplication $\hat{\cdot}$ as introduced in \cite{sugenoPseudoadditiveMeasuresIntegrals1987}. Now we can replace the integral of the probability monad with the universal integral with respect to $\hat{+}$ and $\hat{\cdot}$, which we introduce as:
\begin{equation}\label{eq:cont-fuzzy}
  \sem{x:=m(\vec{T})(F)}
    \;=\;  \int_{a \in \mathcal{I}(s_m)}^{\hat{+}, \hat{\cdot}} \sem{F}_{\nu[x\mapsto a]}\ d \rho_m( \; \cdot\mid \vec{T})(a).
\end{equation}
\noindent
Now, if we want to connect this to a \emph{continuous }t-norm, t-conorm pair $(\otimes, \oplus)$ we can define  $\hat{+} := \oplus$ and $\hat{\cdot}$ as any pseudo-multiplication compatible with $\oplus$. For example just take the normal (bounded) addition and normal multiplication and obtain simply the probabilistic semantics equation~\ref{eq:monad-integral}. The reason we can't generally choose $\hat{\cdot} = \otimes$ is, that most often $\otimes$ and $\oplus$ don't distribute and therefore are not compatible. If we choose a continuous t-conorm $\oplus$ and implicitly take it's dual t-norm $\otimes$ and a pseudo‑multiplication $\hat{\cdot}$ compatible with $\oplus$, we name that $\mathcal{G}_{\oplus}$ and $\oplus$-fuzzy semantics. We also define $\oplus_1 := \{(a,b) \mid a \oplus b = 1 \}$ and observe that $\mathcal{G}_{\oplus}(\{0,1\})=\oplus_1$. Leaving things implicit is canonical in some cases:

\subsection{Canonical pseudo–multiplications for strict continuous
              $t$-conorms}\label{subsec:pseudo‐prod}

Let \(S\colon[0,1]^2\to[0,1]\) be a \emph{strict}\footnote{%
Strict (a.k.a.\ Archimedean) means \(x<y\Rightarrow S(x,t)<S(y,t)\) for
every fixed \(t\in(0,1]\).  All continuous $t$-conorms used in practice
besides \(\max\) and the nilpotent maximum are strict.}
continuous $t$-conorm.  
Then \(S\) admits an \emph{additive generator}
\[
  \phi\colon[0,1]\longrightarrow[0,\infty],
  \qquad
  \phi\text{ strictly increasing},\;
  \phi(0)=0,
  \quad
  S(a,b)=\phi^{-1}\!\bigl(\phi(a)+\phi(b)\bigr).
\]

\begin{definition}[canonical pseudo–product]\label{def:S‐product}
The \emph{pseudo–multiplication} (``$S$-product’’)
associated with \(S\) is the binary operation
\[
  a\;\hat{\cdot}\;x
    \;:=\;
  \phi^{-1}\!\bigl(\phi(a)\,x\bigr),
  \qquad a,x\in[0,1].
\]
\end{definition}

\begin{proposition}\label{prop:pseudo‐prod‐axioms}
The operation \(\hat{\cdot}\) together with \(S\) satisfies
the axioms \textup{(M1)}–\textup{(M5)} of \cite{sugenoPseudoadditiveMeasuresIntegrals1987}; hence
\((S,\hat{\cdot})\) forms a \emph{pseudo-addition / pseudo-multiplication
pair}.  In particular
\[
  a\;\hat{\cdot}\;(x\,\hat{+}\,y)
  = (a\;\hat{\cdot}\;x)\,\hat{+}\,(a\;\hat{\cdot}\;y),
  \qquad
  e:=1\text{ is the left unit of }\hat{\cdot}.
\]
\end{proposition}

\begin{remark}
If the continuous $t$-conorm \(S\) is \emph{not} strict
(e.g.\ \(S(a,b)=\max\{a,b\}\)),  
no additive generator exists; consequently
there is no unique pseudo-multiplication satisfying
\textup{(M1)}–\textup{(M5)}.  One must either relax the axioms or choose
an operation ad hoc.
\end{remark}

\subsection{Relation to the Finite Fuzzy Semantics of ULLER}\label{subsec:relation-to-ullers-fuzzy}

If we now take one of these strict continuous $t$-conorms \(\oplus\), its dual $t$-norm \(\otimes\) and the canonical pseudo-multiplication \(\widehat{\otimes}\) associated with \(\oplus\), equation~\ref{eq:cont-fuzzy}  reduces to the following formula for the interpretation of a computational function symbol \(m\in\mathrm{MFunc}_{\Sigma}\):
\begin{equation}\label{eq:finite-fuzzy}
  \sem{x:=m(\vec{T})(F)}
    \;=\;
    \bigoplus_{a \in \mathcal{I}(s_m)}\sem{F}_{\nu[x\mapsto a]}\;{\widehat{\otimes}} \; \rho_m( a \mid \vec{T}).
\end{equation}

\noindent
This closely resembles the finite fuzzy semantics of ULLER, the difference being that we use the canonical pseudo-multiplication \(\widehat{\otimes}\) instead of the t-norm \(\otimes\), such that this  t-conorm \(\oplus\) sum behaves as a monad, distributes as we would expect it to and is also just a special case of the continuous case. In analogy to $\mathcal{G}_{\oplus}$ the monad of use here is $\mathcal{D}_{\oplus}$, which is simply $\mathcal{G}_{\oplus}$ only with finite supported probability $\oplus$-measures, the same difference as between the Giry monad $\mathcal{G}$ and the distribution monad $\mathcal{D}$.

\begin{table}[h]
\centering
\caption{Examples of pseudo–products}\label{tab:pseudo-products}
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{@{}lll@{}}
\toprule
$t$-conorm \(S(a,b)\) & generator \(\phi\) & pseudo–product \(a\hat{\cdot}x\) \\ \midrule
Probabilistic \(a+b-ab\) & \(-\ln(1-t)\) &
\(1-(1-x)^{\,a}\) \\
Łukasiewicz \(\min\{1,a+b\}\) & \(t\) &
\(\max\{0,\,x+a-1\}\) \\[4pt]
Einstein \(\dfrac{a+b}{1+ab}\) & \(\tfrac{t}{1-t}\) &
\(\dfrac{ax}{1+ax}\) \\ \bottomrule
\end{tabular}
\end{table}

\noindent
The table~\ref{tab:pseudo-products} shows some examples of pseudo-multiplications for strict continuous $t$-conorms of which we already have used the probabilistic one in the probabilistic semantics in section~\ref{subsec:prob-sem} to define our conjunction.

Now, having defined the pseudo-Giry monads, we can also add it to our NeSy shifts diagram of section~\ref{subsec:nesy-shifts}, which we had already extended in section~\ref{subsec:poss-monad} and now extend it one last time. The arrows between the Giry monad $\mathcal{G}$ and the pseudo-Giry monad $\mathcal{G}_\oplus$ arises only when taking the continuous $t$-conorm $\oplus$ as the normal (bounded) addition, it's dual $t$-norm $\otimes$ as the Łukasiewicz $t$-norm and the pseudo-multiplication $\hat{\cdot}$ as normal multiplication, since then we simply obtain the probabilistic semantics of section~\ref{subsec:prob-sem} and the normal Giry monad $\mathcal{G}$:

% https://q.uiver.app/#q=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
\[\begin{tikzcd}[cramped,sep=scriptsize]
	&& {\tilde{\Pi}(X)} &&&& {\tilde{\Pi}_\phi(X)} \\
	\\
	{ \mathcal{P}_{\neq \emptyset}(X)} &&&& {\mathcal{D}(X)} \\
	\\
	&& {\mathcal{G} (X)} &&&& {\mathcal{O}(X)} \\
	\\
	{\mathrm{Id}_\mathbf{Set}(X)} &&&& {\mathrm{Id}_\mathbf{Set}(X)} \\
	\\
	&& {\mathcal{G}_\oplus (X)} && {\mathcal{D}_\oplus (X)}
	\arrow["\phi"{description, pos=0.7}, hook, two heads, from=1-3, to=1-7]
	\arrow["\argmax"{description}, two heads, from=1-3, to=3-1]
	\arrow["{(\mathrm{unif})}"{description}, hook, from=3-1, to=5-3]
	\arrow["{\varphi \circ \pi}"{description}, from=3-5, to=1-3]
	\arrow["\argmax"{description}, two heads, from=3-5, to=3-1]
	\arrow[hook, from=3-5, to=5-3]
	\arrow["{(id)}"{description, pos=0.7}, hook, two heads, from=5-3, to=5-7]
	\arrow["{(\oplus=+,\otimes= Luk,\widehat\otimes=\cdot)}"{description, pos=0.7}, hook, two heads, from=5-3, to=9-3]
	\arrow["{\{\cdot \}}"{description}, hook, from=7-1, to=3-1]
	\arrow["\delta"{description}, hook, from=7-1, to=5-3]
	\arrow["id"{description, pos=0.2}, hook, two heads, from=7-1, to=7-5]
	\arrow["\delta"{description}, hook, from=7-1, to=9-3]
	\arrow["\delta"{description, pos=0.3}, hook, from=7-5, to=3-5]
	\arrow["\delta"{description}, hook, from=7-5, to=5-3]
	\arrow["\delta"{description}, hook, from=7-5, to=9-3]
	\arrow["\delta"{description}, hook, from=7-5, to=9-5]
	\arrow[hook, from=9-5, to=9-3]
\end{tikzcd}\]





\section{Type Checking}\label{subsec:type-checking}

We explain why the formulas in Table~\ref{tab:semantics} (categorical semantics) are well-typed. For a given $\mathcal{I}(f)\; \circ < \sem{T_1} \circ \pi_{1}  ,\dots, \sem{T_n} \circ \pi_{n} >$, we define $\pi_{i} := \mathcal{V}_{H} \to \mathcal{V}_{T_i}$ as the projection on the $i$–th component of the product and where $H:=f(T_1,\dots,T_n)$. If for example $T_1$ is a constant, we  have $\mathcal{V}_{T_1} = 1$ since a constant has empty context. In this case $\pi_{1}$ is the unique terminal arrow. Similarly, for a given pair of formulas $< \sem{F} \circ \pi_{F} , \sem{G} \circ \pi_{G} >$  we define $\pi_{F}: \mathcal{V}_{F} \times \mathcal{V}_{G} \to \mathcal{V}_{F}$ as the projection on the $F$–th component of the product, and for $G$ alike. For the quantifiers we type check as follows:


\begin{align*}
\mathcal{V}_F
  &= \prod_{\,y:t\in\Gamma_F} \mathcal{I}(t) \cong
     \Bigl(\,\prod_{\,y:t\in\Gamma_F\setminus x:s} \mathcal{I}(t)\Bigr)
     \times \mathcal{I}(s).
\end{align*}
\[
  \sem{F} :
    V_{F\!\backslash x:s} \times \mathcal{I}(s)
    \;\longrightarrow\;
    \mathcal{T}\Omega,
\qquad
  \Lambda_{s}\bigl(\sem{F}) :
    V_{F\!\backslash x:s}
    \;\longrightarrow\;
    \mathcal{T}\Omega^{\mathcal{I}(s)},
\]
\[
\bigwedge_{\mathcal{I}(s)},\;
\bigvee_{\mathcal{I}(s)} :
   \mathcal{T}\Omega^{\mathcal{I}(s)}
   \;\longrightarrow\;
   \mathcal{T}\Omega.
\]

\noindent
Of course equation~\ref{eq:monad-integral} also needs some more explanation. The $(-)^{*}$ operation is the lifting of the monad $\mathcal{T}$. We define for a computational function symbol \(m\in\mathrm{MFunc}_{\Sigma}\):
\[
  V_{F\!\backslash x:m}
    \;:=\;
    \prod_{\,y:t\in\Gamma_{F}\!\backslash x:s_m} \mathcal{I}(t).
\]
\noindent
 where $s_m$ is the sort of $m$. Set $H:=(x:=m(T_1,\dots,T_n)(F))$. We also observe the following typing facts:
\[
  \sem{F} :
    V_{F\!\backslash x:m} \times \mathcal{I}(s_m)
    \;\longrightarrow\;
    \mathcal{T}\Omega,
\qquad
  \sem{F}^{*} :
    \mathcal{T}\!\bigl(V_{F\!\backslash x:m} \times \mathcal{I}(s_m)\bigr)
    \;\longrightarrow\;
    \mathcal{T}\Omega.
\]
\[
  \mathcal{S} :
    V_{F\!\backslash x:m} \times \mathcal{T}\mathcal{I}(s_m)
    \;\longrightarrow\;
    \mathcal{T}\!\bigl(V_{F\!\backslash x:m} \times \mathcal{I}(s_m)\bigr),
\qquad
  \sem{F}^{*} \circ \;\mathcal{S} :
    V_{F\!\backslash x:m} \times \mathcal{T}\mathcal{I}(s_m)
    \;\longrightarrow\;
    \mathcal{T}\Omega,
\]
\[
  \Lambda_{m}\bigl(\sem{F}^{*} \circ \;\mathcal{S}) :
    V_{F\!\backslash x:m}
    \;\longrightarrow\;
    \mathcal{T}\Omega^{\mathcal{T}\mathcal{I}(s_m)},
\qquad
  \Lambda_{m}\bigl(\sem{F}^{*} \circ \;\mathcal{S})\;\circ\;\mathrm{\pi}_{V_{F\!\backslash x:m}} :
    V_{H}
    \;\longrightarrow\;
    \mathcal{T}\Omega^{\mathcal{T}\mathcal{I}(s_m)}.
\]
\[
  \mathcal I(m) :
    \prod_{i=1}^{n} \mathcal{I}(s_{T_i})
    \;\longrightarrow\;
    \mathcal{T}\!\bigl(\mathcal{I}(s_m)\bigr),
\qquad
  \bigl\langle
    \llbracket T_1\rrbracket\!\circ\!\pi_1,\,
    \dots,\,
    \llbracket T_n\rrbracket\!\circ\!\pi_n
  \bigr\rangle :
    V_{H}
    \;\longrightarrow\;
    \prod_{i=1}^{n} \mathcal{I}(s_{T_i}),
\]
\[
    \lbrack m(T_1,\dots,T_n) \rbrack := \mathcal I(m)\circ
      \bigl\langle
        \llbracket T_1\rrbracket\!\circ\!\pi_1,\dots,
        \llbracket T_n\rrbracket\!\circ\!\pi_n
      \bigr\rangle:
    V_{H}
    \;\longrightarrow\;
    \mathcal{T}\mathcal{I}(s_m).
\]

\[
    \mathrm{ev}: \mathcal{T}\mathcal{I}(s_m) \times \mathcal{T}\Omega^{\mathcal{T}\mathcal{I}(s_m)} \to \mathcal{T}\Omega,
\]
\[
  \bigl\langle \lbrack m(T_1,\dots,T_n) \rbrack , \;  \Lambda_{m}\bigl(\sem{F}^{*} \circ \mathcal{S})\circ\mathrm{\pi}_{V_{F\!\backslash x:m}} 
       \bigr\rangle:
    \mathcal{V}_H
    \;\longrightarrow\;
    \mathcal{T}\mathcal{I}(s_m) \times \mathcal{T}\Omega^{\mathcal{T}\mathcal{I}(s_m)},
\]
\[
  \mathrm{ev} \circ \bigl\langle \lbrack m(T_1,\dots,T_n) \rbrack , \;  \Lambda_{m}\bigl(\sem{F}^{*} \circ \mathcal{S})\circ\mathrm{\pi}_{V_{F\!\backslash x:m}} 
       \bigr\rangle:
    \mathcal{V}_H
    \;\longrightarrow\;
    \mathcal{T}\Omega.
\]
\noindent
This we can also write more compactly as:
\[
\sem{F}^{*} \circ \mathcal{S} \circ \langle\mathrm{\pi}_{V_{F\!\backslash x:m}}, \; \lbrack m(T_1,\dots,T_n) \rbrack \rangle: 
    \mathcal{V}_H
    \;\longrightarrow\;
    \mathcal{T}\Omega.
    \]


\end{document}
